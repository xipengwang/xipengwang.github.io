{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acce74ae",
   "metadata": {},
   "source": [
    "# Language Vision Model (LVM)\n",
    "\n",
    "[Course Slides](https://docs.google.com/presentation/d/1A64W7qUGUvVhfOHneNiIdDr-rC55IZr0DWJGR6NmVkI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74120ac",
   "metadata": {},
   "source": [
    "## Classic Paper List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6a731",
   "metadata": {},
   "source": [
    "- [AlexNet](https://dl.acm.org/doi/pdf/10.1145/3065386)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c1d30",
   "metadata": {},
   "source": [
    "- ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962565b",
   "metadata": {},
   "source": [
    "- Transformer (Gives a way for feature extraction with self-attention mechanism)\n",
    "    - $Attention(Q, K, V) = Softmax_{row}(\\frac{Q_{NxD_k} K_{MxD_k}^T}{\\sqrt{D_k}}) * V_{MxD_k}$\n",
    "        - $Q_{NxD_k}$ is query,  $K_{MxD_k}$ and  $V_{MxD_k}$ are keys and values which have the same dimension.\n",
    "        - Each row in $\\frac{Q_{NxD_k} K_{MxD_k}^T}{\\sqrt{D_k}}$ contains individual weight($M$ weights) for each value ($M$ values).\n",
    "    - It uses self-attention. This means keys, values and queries are the same for encoder module.  \n",
    "    - It can be used as feature extraction block. The input and output will have the same dimension. \n",
    "        - It uses multi-heads so it can have things to learn since attention is just a dot products for key and query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a33808",
   "metadata": {},
   "source": [
    "- [BERT](https://arxiv.org/abs/1810.04805) (Gives a way for pre-training LLM with masked words)\n",
    "    - It is used as a pre-trained model on large language dataset\n",
    "    - It uses WordPiece for tokens\n",
    "    - Unlike for machine translation (using single direction information), pre-trained model could use Bidirectional information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8055dd",
   "metadata": {},
   "source": [
    "- [ViT](https://arxiv.org/abs/2010.11929) (Gives a way for using image patches as input for transformer blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce11f7",
   "metadata": {},
   "source": [
    "- MAE (Gives a way for contrastive learning based LLM without running out memory)\n",
    "\n",
    "- Swin Transformer\n",
    "\n",
    "- CLIP\n",
    "\n",
    "- GPT\n",
    "\n",
    "- DALL-E2(unCLIP)\n",
    "\n",
    "- [ViLT](https://arxiv.org/abs/2102.03334)\n",
    "    - It combines ideas from BERT(language features) and ViT(visual features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f67181",
   "metadata": {},
   "source": [
    "## [BERT](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647b422",
   "metadata": {},
   "source": [
    " ##  [ViLT](https://arxiv.org/abs/2102.03334)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae958ddf",
   "metadata": {},
   "source": [
    "## [DALL-E2](https://cdn.openai.com/papers/dall-e-2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d99d6",
   "metadata": {},
   "source": [
    "- Auto Encoder(AE)\n",
    "    - An encoder for encoding an image, which can be decoded to original image by a decoder.\n",
    "- De-noise Auto Encoder (DAE)\n",
    "    - Add noises to input image while the target is still the original image.\n",
    "- Masked Auto Encoder (MAE)\n",
    "    - Add masks to input image while the target is still the original image.\n",
    "- Variational Auto Encoder (VAE)\n",
    "    - An encoder to generate a Gaussian Distribution ($\\mu, \\Sigma$)\n",
    "- Vector Quantised-Variational AutoEncoder (VQ-VAE)\n",
    "    - An encoder to generate a feature index map (features are in a $KxD$ matrix codebook) instead of a continuous distribution.\n",
    "- Diffusion Model \n",
    "    - Add noises and then de-noise.\n",
    "    - DNN is used to predict noise instead of image.\n",
    "    - Uses U-Net with skip connection + time embedding (which de-noising step) + attention(transformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
