{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stone-vermont",
   "metadata": {},
   "source": [
    "# Multi-view Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-configuration",
   "metadata": {},
   "source": [
    "## Camera Intrinsics and Extrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-mexico",
   "metadata": {},
   "source": [
    "### Basics of Pinhole Camera Model\n",
    "The projection is shown as below, where $S$ is the sensor frame, $I$ is the image frame, $C$ is the camera frame, and $W$ is the world frame. $I$ frame normally has only a constant offset to $C$, which is so called camera constant.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1\n",
    "\\end{bmatrix} = T_{SC} T_{IC} T_{CW} \\begin{bmatrix} X \\\\ Y \\\\ Z \\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-wrestling",
   "metadata": {},
   "source": [
    "Extrinsic parameter is $T_{CW}$ which typically has 6 DoF - 3 for position and 3 for orientation. $O^W_C$ is the world origin expressed in the camera frame $C$. $O^C_W$ is the camera origin expressed in the world frame $W$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{CW} = \n",
    "\\begin{bmatrix}\n",
    "R_{CW},& O^W_{C} \\\\\n",
    "0,& 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{CW} = \n",
    "\\begin{bmatrix}\n",
    "R_{CW},& -R_{CW} O^C_W \\\\\n",
    "0,& 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-terminology",
   "metadata": {},
   "source": [
    "Intrinsic parameter is $T_{SC} T_{IC}$ without considering non-linear distortions. If we consider image plane is at the negative z direction. Then camera constant $c$ will be negative. $x_H$ and $y_H$ are translation from image frame center to sensor frame center. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{SC} T_{IC} & = \n",
    "\\begin{bmatrix}\n",
    "1,& 0, & x_H \\\\\n",
    "0,& 1, & y_H \\\\\n",
    "0,& 0, & 1\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "c,& 0, & 0 \\\\\n",
    "0,& c, & 0 \\\\\n",
    "0,& 0, & 1\n",
    "\\end{bmatrix} \\\\ \n",
    "& = \\begin{bmatrix}\n",
    "1,& s, & x_H \\\\\n",
    "0,& 1+m, & y_H \\\\\n",
    "0,& 0, & 1\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "c,& 0, & 0 \\\\\n",
    "0,& c, & 0 \\\\\n",
    "0,& 0, & 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "K = T_{SC} T_{IC} & = \n",
    "\\begin{bmatrix}\n",
    "c_x,& s_{xy}, & x_H \\\\\n",
    "0,& c_y, & y_H \\\\\n",
    "0,& 0, & 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-sustainability",
   "metadata": {},
   "source": [
    "Non-linear distortion could be caused by non-perfect lens so that each pixel projected onto sensor plane is shifted a little based on its position. $x_u$ and $y_u$ are undistorted projected points on the normalized image plane where $depth = 1$ ($x_u = \\frac{X_C}{Z_C}, y_u = \\frac{Y_C}{Z_C}$, $Z_C$ is the depth). $q$ are the parameters for distortion models, such as barrel distortion, tangent distortion, etc. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_d =& x_u + \\Delta(x_u, q) \\\\\n",
    "y_d =& y_u + \\Delta(y_u, q)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_d = H(x_u)x_u\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1\n",
    "\\end{bmatrix} = T_{SC} T_{IC} \\begin{bmatrix} x_d \\\\ y_d \\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-architecture",
   "metadata": {},
   "source": [
    "### Mapping\n",
    "\n",
    "#### Inverse map from $uv$ to $x_d$\n",
    "$$\n",
    "\\begin{align}\n",
    "x_d = K^{-1}\\begin{bmatrix} u \\\\ v \\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Inverse map from $x_d$ to $x_u$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "[x_{u}]_{i+1}= [H([x_{u}]_i)]^{-1}x_d\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Inverse map from $x_u$ to $X_c$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X_C = \\lambda x_u\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "X_W = O_W^C + R_{CW}^{-1} X_C\n",
    "\\end{align}\n",
    "$$\n",
    "Where $\\lambda$ is the depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "average-penetration",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map world points to sensor frame\n",
      "p_w: [ 1  0 -5  1]\n",
      "p_c: [ 2  0 -5] depth: -5\n",
      "p_s: [400. 200.   1.]\n",
      "\n",
      "Map sensor points to world frame\n",
      "ray: [-0.4  0.   1. ]\n",
      "p_c: [ 2. -0. -5.]\n",
      "p_w: [ 1  0 -5  1]\n"
     ]
    }
   ],
   "source": [
    "# Mapping and inverse mapping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print('Map world points to sensor frame')\n",
    "p_w = np.array([1, 0, -5, 1])\n",
    "print(f'p_w: {p_w}')\n",
    "T_cw = np.array([[1, 0, 0, 1], \n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]])\n",
    "R_cw = T_cw[0:3, 0:3]\n",
    "O_w = -R_cw.T.dot(T_cw[0:3, 3])\n",
    "\n",
    "p_c = T_cw.dot(p_w)\n",
    "\n",
    "depth = p_c[2]\n",
    "p_c = p_c[0:3]                \n",
    "print(f'p_c: {p_c}', f'depth: {depth}')\n",
    "\n",
    "K = np.array([[-500, 0, 200], [0, -500, 200], [0, 0, 1]])\n",
    "\n",
    "# Depth = 1\n",
    "p_nc = p_c / depth\n",
    "\n",
    "uv = K.dot(p_nc)\n",
    "print(f'p_s: {uv}')\n",
    "print('\\nMap sensor points to world frame')\n",
    "ray = np.linalg.inv(K).dot(uv)\n",
    "print(f'ray: {ray}')\n",
    "\n",
    "p_c = depth * ray\n",
    "print(f'p_c: {p_c}')\n",
    "\n",
    "p_W = O_w + depth * R_cw.T.dot(ray)\n",
    "print(f'p_w: {p_w}')\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-senator",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-bridal",
   "metadata": {},
   "source": [
    "#### DLT: Direct Linear Transform\n",
    "\n",
    "Key ideas:\n",
    "- Projection matrix $P = T_{SC} T_{IC} T_{CW}$ has 11 DoF.\n",
    "- Given a 2D-to-3D correspondence, we can get two constraints for solving P.\n",
    "- We need at least 6 correspondences so that we will have 12 constraints to solve $P$ with 11 DoF.\n",
    "- Use SVD to find the solution - right singular vector with least singular value.\n",
    "- $ P = [KR| -KRO_W^C]$, so once we get $P$, we can get $KR$ and $O_C^C$\n",
    "- Use QR decomposition on $(KR)^{-1}$ to find $K$ and $R$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-coalition",
   "metadata": {},
   "source": [
    "#### Zhang's homography approach\n",
    "\n",
    "Key ideas:\n",
    "- Use planer object so that $Z_W$ is always 0. \n",
    "- Instead of getting $P$, we are solving equations to get homography matrix $H$. \n",
    "- We need at least 4 points on each image to solve $H$.\n",
    "- Each homography solution gives 2 constraints on $K^TK$.\n",
    "- $K^TK$ is a symmetric matrix with 6 DoF. So we need at least 3 images with each giving us 2 constraints on $K^TK$.\n",
    "- Find $K^TK$, then do Choleskey decomposition to find $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-manhattan",
   "metadata": {},
   "source": [
    "#### Non-linear Optimization with Gauss-Newton or LM \n",
    "\n",
    "Key ideas:\n",
    "- Use Zhang's approach for initialization.\n",
    "- $K, q, R_i, t_i = \\underset{K, q, R_i, t_i}{\\operatorname{argmin}} {\\sum_n\\sum_i}\\|x_{ni} - \\hat{x}(K, q, R_i, t_i, X_{ni})\\|^2$.\n",
    "- Note that we can set the planar object corner as world origin (0, 0, 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-latter",
   "metadata": {},
   "source": [
    "### Perspective-n-Points\n",
    "\n",
    "Given n points in 3D world and its correspondence in 2D image, find the calibrated camera extrinsic pose.\n",
    "\n",
    "#### P3P\n",
    "key ideas:\n",
    "- There are 4 solutions in front of camera. We need one additional point to resolve the ambiguity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-reform",
   "metadata": {},
   "source": [
    "### Fundamental Matrix and Essential Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-biodiversity",
   "metadata": {},
   "source": [
    "#### Fundamental Matrix\n",
    "Based on the $O_1O_2$, $O_1X$ and $O_2X$ form a plane, aka $O_1X (\\cdot O_1O_2 \\times O_1X) = 0$, we can get \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_1^T (R_1^{-1}K_1^{-1})^T S_{b_{12}} R_2^{-1}K_2^{-1}x_2 = 0\n",
    "\\end{align}\n",
    "$$\n",
    "Where $S_b$ is the skew matrix of vector $O_1O_2$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_1^TF_{12}x_2 &= 0 \\\\\n",
    "F_{12} &= K_1^{-T}R_1^{-T} S_{b_{12}} R_2^{-1}K_2^{-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then suppose we have projection matrix $P_1 = [A_1 | a_1] = [KR | -KRO_1]$, then we can get $b_{12} = O_1O_2 = A_2^{-1}a_2 - A_1^{-1}a_1$. Then \n",
    "$$\n",
    "\\begin{align}\n",
    "F = A_1^{-T}S_{b_{12}}A_2^{-1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-apollo",
   "metadata": {},
   "source": [
    "#### Essential Matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_1^TK_1^{-T}E_{12}K_2^{-1}x_2 &= 0 \\\\\n",
    "F &= K_1^{-T}E_{12}K_2^{-1} \\\\\n",
    "E_{12} &= R_1^{-T} S_{b_{12}} R_2^{-1}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-verification",
   "metadata": {},
   "source": [
    "#### Epipolar Constraint\n",
    "\n",
    "Important elements:\n",
    "- Epipolar axis: $b_{12} = O_1O_2$\n",
    "- Epipolar plane: $O_1O_2X$\n",
    "- Epipoles: For image 1, the epipole is the point that camera center $O_2$ projected onto image 1.\n",
    "    - Which is also the intersected point between $O_1O_2$ and image 1 plane.\n",
    "    - Epipole in image 1 is in the null space of $F_{12}^T$ because $e_1^TF_{12}x_2 = 0$ is always true.\n",
    "        - This can be obtained using eigen decomposition and find the eigen vector with eigen value as 0.\n",
    "        - **So Fundamental Matrix F has rank as 2...**\n",
    "- Epipolar line: For image 1, the epipolar line is the line that ray $O_2X$ projected onto image 1.\n",
    "    - Which is also the intersected line between epipolar plane $O_1O_2X$ and image 1 plane.\n",
    "    - $F_{12}x_2$ is the epipolar line in image 1 because $x_1$ lies on it, aka $x_1^TF_{12}x_2 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-analyst",
   "metadata": {},
   "source": [
    "#### Direct Solution for Estimating Fundamental Matrix and Essential Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-awareness",
   "metadata": {},
   "source": [
    "Key ideas: \n",
    "- Use DLT to solve $F$ similar as estimating homography matrix $H$. $x_1^TF_{12}x_2 = 0$\n",
    "    - There are 8 unknowns in F so we need at least 8 correspondences. \n",
    "    - $Rank(F) = 2$\n",
    "        - $F = USV^T$, then $F \\approx U\\hat{S}V^T$ where $\\hat{S}$ is generated by setting the least singular value as 0.\n",
    "    - In reality, using normalized pixel values makes solution more numerically stable.\n",
    "- Use DLT to solve $E$ similar as estimating homography matrix $H$. ${x_k}_1^TE_{12}{x_k}_2 = 0$\n",
    "    - There are 8 unknowns in F so we need at least 8 correspondences.\n",
    "    - $Rank(F) = 2$\n",
    "        - $F = USV^T$, then $F \\approx U\\hat{S}V^T$ where $\\hat{S}$ is generated by setting the least singular\n",
    "        - **We also need to make first two singular value the same. We can all set them as 1.** so it is skew-symmetric??\n",
    "- 5 Point algorithm for finding $E$\n",
    "    - RANSAC idea:\n",
    "        - Minimal number of points to fit a model: $s$\n",
    "        - Outlier ratio: $e$\n",
    "        - Draw a single inlier probability $p = 1-e$\n",
    "        - Draw $s$ inliers $p = (1-e)^s$\n",
    "        - Failing 1 time probability $p_f = 1-(1-e)^s$\n",
    "        - Failing T time probability $p_f = (1-(1-e)^s)^T$\n",
    "        - If we want to have success probability at least p, then $p > 1-p_f$.\n",
    "        - **$T = \\frac{log(1-p)}{log(1-(1-e)^s)}$**\n",
    "        \n",
    "        \n",
    "##### Find $R$ and $t$ from $E$\n",
    "- $E_{12} = R_{21} [t_{12}]_\\times $ which assumes camera 2 is at the world origin.\n",
    "- $E_{12} = [t_{12}]_\\times R_{12}^T $ which assumes camera 1 is at the world origin.\n",
    "- [4 solutions](https://youtu.be/zX5NeY-GTO0?t=2934)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-holder",
   "metadata": {},
   "source": [
    "### Camera Models\n",
    "#### Pinhole Camera Model\n",
    "#### Unified Camera Model\n",
    "#### Extended Unified Camera Model\n",
    "#### Kannala-Brandt Camera Model\n",
    "#### Double Sphere Camera Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-sitting",
   "metadata": {},
   "source": [
    "## Optical Flow\n",
    "\n",
    "The goal is to find $ \\Delta u, \\Delta v = \\underset{\\Delta u, \\Delta v}{\\operatorname{argmin}} \\|I_1(u, v) - I_2(u + \\Delta u, v + \\Delta v)\\|^2$.\n",
    "\n",
    "We can minimize the error iteratively as in [this](https://arxiv.org/abs/1603.03590). \n",
    "$$\n",
    "\\Delta u, \\Delta v = \\underset{\\Delta u, \\Delta v}{\\operatorname{argmin}} \\|I_1(u, v) - I_2(u + u^* + \\Delta u, v + v^* + \\Delta v)\\|^2 \\\\\n",
    "u^* += \\Delta u \\\\\n",
    "v^* += \\Delta v\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
