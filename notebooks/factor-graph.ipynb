{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "negative-penetration",
   "metadata": {},
   "source": [
    "# Factor Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-liberia",
   "metadata": {},
   "source": [
    "## Formulate SLAM as a Factor Graph\n",
    "Factor graph is a nice representation for optimization problems:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}}\\prod_i \\Phi_i\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}}\\prod_i \\phi_i(X, Z)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "A simple factor graph is shown below. Circles represent state variables, e.g robot poses, and squares represent constraints among variables, e.g. relative transformation. The corresponding optimization problem is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}}\\prod_{i=0}^3 \\Phi_i\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}}\\phi_0(z_0; x_0, x_1)\\phi_1(z_1; x_0, x_2)\\phi_2(z_2; x_1, x_2)\\phi_3(z_3; x_2)\n",
    "\\end{align}\n",
    "$$\n",
    "where $x$ are state variables to be optimized, and $z$ are observations related to states though a factor potential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handled-product",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAkACQAAD/4QCARXhpZgAATU0AKgAAAAgABQESAAMAAAABAAEAAAEaAAUAAAABAAAASgEbAAUAAAABAAAAUgEoAAMAAAABAAIAAIdpAAQAAAABAAAAWgAAAAAAAACQAAAAAQAAAJAAAAABAAKgAgAEAAAAAQAABRCgAwAEAAAAAQAAAmgAAAAA/+0AOFBob3Rvc2hvcCAzLjAAOEJJTQQEAAAAAAAAOEJJTQQlAAAAAAAQ1B2M2Y8AsgTpgAmY7PhCfv/iAjRJQ0NfUFJPRklMRQABAQAAAiRhcHBsBAAAAG1udHJSR0IgWFlaIAfhAAcABwANABYAIGFjc3BBUFBMAAAAAEFQUEwAAAAAAAAAAAAAAAAAAAAAAAD21gABAAAAANMtYXBwbMoalYIlfxBNOJkT1dHqFYIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmRlc2MAAAD8AAAAZWNwcnQAAAFkAAAAI3d0cHQAAAGIAAAAFHJYWVoAAAGcAAAAFGdYWVoAAAGwAAAAFGJYWVoAAAHEAAAAFHJUUkMAAAHYAAAAIGNoYWQAAAH4AAAALGJUUkMAAAHYAAAAIGdUUkMAAAHYAAAAIGRlc2MAAAAAAAAAC0Rpc3BsYXkgUDMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdGV4dAAAAABDb3B5cmlnaHQgQXBwbGUgSW5jLiwgMjAxNwAAWFlaIAAAAAAAAPNRAAEAAAABFsxYWVogAAAAAAAAg98AAD2/////u1hZWiAAAAAAAABKvwAAsTcAAAq5WFlaIAAAAAAAACg4AAARCwAAyLlwYXJhAAAAAAADAAAAAmZmAADypwAADVkAABPQAAAKW3NmMzIAAAAAAAEMQgAABd7///MmAAAHkwAA/ZD///ui///9owAAA9wAAMBu/8AAEQgCaAUQAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/bAEMAHBwcHBwcMBwcMEQwMDBEXERERERcdFxcXFxcdIx0dHR0dHSMjIyMjIyMjKioqKioqMTExMTE3Nzc3Nzc3Nzc3P/bAEMBIiQkODQ4YDQ0YOacgJzm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubm5v/dAAQAUf/aAAwDAQACEQMRAD8A6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiio3lSP7x/CiwElNZ1T7xxVF7l24X5RVcnPJrVU+5m6nYvtdIPugmoTdOegAqtRVqCIc2TefKf4qb5sn941HRT5UTdkvnSD+I04XEo75qCijlQXZbF0f4h+VTrcRt3x9azaKl00Ups2AQeRRWSrshypxVuO6B4kGPcVDptbGimmW6KQEEZHIpazLCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/9DpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooJAGTWbPcGT5V4X+dVGNyZSsTS3OPlj/ADqkSScmm0V0KKWxi22LS02imSLS02igBaWm0UALS02igBaWm0UALS02igCVJXjOVP4VoxTLKOOD6Vk0oJByODUygmXGTRtUVXgnEnytw386sVztW0ZsncKKKKQwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/0ekooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKp3U20eWvU9acVd2E3YhuJ952L90frVWkorqStoYN3FopKKYhaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBwJByK04JhKuD94dayqcjlGDL1FTKN0VGVjbopkbiRA470+uU3CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//S6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBkjiNC57VisxYlj1NW7yTLCMduT9apV0042VzGbu7C0UlFaEC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAFu1l2PsPRv51qVgVtQSebGG79D9awqx6msH0JaKKKxNAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//T6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACkJCgsegparXb7YT78U0ruwm7GU7F2LHuc02kortOcWikooAWikooAWikooAWikooAWikooAWikooAWikooAWikooAWikooAWikooAWr1k+HMZ781QqSJ9kqt6Gpkrqw07M3aKKK4zoCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD//1OkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArOv24Rfqa0ayb8/vQP9mtKS94mexToptFdZiOoptFADqKbRQA6im0UAOop0cbynagyatCxlI5IFS5JbjSbKdFLIjRuUbqKnitJZV3cAe9DaSuKxXop8sTQvsaoqa1AdRTaKYDqKbRQA6im0UAOoptFADqKbRQB0Mbbo1b1ANPqvanNup/z1qxXDJWZutgooopDCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/V6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACse+/1/4Ctise//ANcP90f1rWj8RE9ilRSUV1GQtFJRQAtFJRQAtFJRQA4Ejoa0LB/naPsRms2rNoSLhcVM1eLHHc0J4FaYSvwgHP4VSa8lL7kOB2FXb/d5HHTIzWNWdNXV2VJ2ehLJI8rb3OTUdKqs7BVGSatG12YEsiqT2rVtLQmzZUoqea3kh5bkHuKr0009hWFopKKAFopKKAFopKKAFopKKANyz/491/H+dWqrWf8Ax7r+P86s1xT3ZutgoooqRhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH//1ukooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArK1EfMjeoIrVqlfrug3f3Tn+laU3aSJlsYtFJRXYYi0UlFAC0UlFAC0UlSwBTMofpnnNDAjrRTFpD5jf6x+g9BVmSO0iPmsAMdAO/4VkzStM5dv8A9VZJ8/oXaxtygTWxx/EuR/OsNEeRtiDJrXspVaEITyvH4VVneG3Vo7f7zdT6D0qINpuI5a6k9jEEjMrdT/IVlyOZHLnua2V+Wy/4AT+lYVXT1bYpbJGxZsJoGifkDj8DWW6mNyh7HFXtOPzOPYVBejFy3vj+VEdJtA9kyrRSUVqQLRSUUALRSUUALRSU9F3uqepxQB0EA2woPYVLRRXA2dAUUUUgCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP//X6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACmSIJI2Q9xin0UAcuQQcHqKSrl/F5c24dH5/HvVKvQi7q5g1YWikopiFopKKAFopKKAFopKKAFopKKAN6P57Hj+4RWFWrp8wKmBuvUVnTRNDIUPbp9Kxp6SaLlsmX9NHzOfYVWvTm5b2x/Kr1qBbWxll4zz/hWQ7l2LnqTmiOs2we1hKKSitiBaKSigBaKSigBavWEe+bf2UfrVCt6xi8uAE9W5/wAKzqytEqK1LlFFFcRsFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH//0OkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooArXcPnwlR94ciudrq6xL+38t/OX7rdfY10UZ/ZZE11M+ikorqMxaKSigBaKSigBaKSigBaKSigBQSDkHBFWvts+BuIbHqBVSik4p7hcmlnlmOZGzioqSihK2wC0UlFMBaKSigBaKSgZJwKALNrD58oXsOT9K6Oqtpb+RFg/ePJq1XFVnzM1irBRRRWRQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf//R6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAprosilHGQadRQBzNzA1vJtPQ9D61VMiBghPJrY1a8hhi8kjdI3QenvWClpLERLcKQW5Ga64VXKy6mbjYsUUlFdBAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtbFha4xPIP90f1qvbWyIn2q6O2McgHvW6rKyhlOQeQRXNWq/ZRcY9WLRRRXKaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/S6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArL1HUVs12JzKeg9Pc0ajqK2a7E5lPQenuaqadpzFvtt7y55AP8zQAadpzFvtt7y55AP8AM1tyxJMhSQZFSUUJgc5c2cludw+ZPX/GqVdh14NZlxpqP80Pyn07f/WrrhX6SM3HsYVFSSwywnbIpFRV0LXYgWikopgLRSUUALRSUUALRSUUALRSVdgsZ5uSNi+p/wAKltLVjsVACx2qMk9hW1aaeFxJPyey/wCNXYLWK3HyDJ7k9asVy1K19IlqPcrXVrHdwmGT6g+hrAtrmfSZ/sl3zEeh9Pce1dRVa7tIryIxyD6HuDXOWWFZWUMpyDyCKWuXtrmfSZ/sl3zEeh9Pce1dOrKyhlOQeQRQAtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB/9PpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKy9R1FbNdicynoPT3NGo6itmuxOZT0Hp7mqmnacxb7be8ueQD/M0AGnacxb7be8ueQD/ADNb9FFABRRRQAUUUUAIyqw2sAQexrPl02B+Uyh9uR+VaNFVGTWzE0c9Jplwn3MOPbg/rVN4Jo/vowx7V1tFbLES6k8hxtFdgVVvvAH61H9ntz1jX8hV/WV2FyHJ0oBY4UZPtXWCCFfuoo+gFSgAdKHieyHyHLJZ3Un3Yz+PH86vR6U55lcD2HNbdFZuvJ7D5UVobO3g5Rcn1PJqzRRWLbe5QUUUUgCiiigCtd2kV5EY5B9D3BrAtrmfSZ/sl3zEeh9Pce1dRVa7tIryIxyD6HuDQBYVlZQynIPIIpa5e2uZ9Jn+yXfMR6H09x7V06srKGU5B5BFAC0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9TpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArL1HUVs12JzKeg9Pc0ajqK2a7E5lPQenuaqadpzFvtt7y55AP8zQAadpzFvtt7y55AP8AM1v0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAVru0ivIjHIPoe4NYFtcz6TP8AZLvmI9D6e49q6iq13aRXkRjkH0PcGgCwrKyhlOQeQRS1y9tcz6TP9ku+Yj0Pp7j2rp1ZWUMpyDyCKAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/1ekooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKy9R1FbNdicynoPT3NGo6itmuxOZT0Hp7mqmnacxb7be8ueQD/M0AGnacxb7be8ueQD/ADNb9FFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAVru0ivIjHIPoe4NYFtcz6TP8AZLvmI9D6e49q6iq13aRXkRjkH0PcGgCwrKyhlOQeQRS1y9tcz6TP9ku+Yj0Pp7j2rp1ZWUMpyDyCKAFooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/W6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACq32j/Z/WrNZtY1ZuNrFwSe5Z+0f7P60faP9n9arUVj7WXcvlRZ+0f7P60faP8AZ/Wq1FHtZdw5UWftH+z+tH2j/Z/Wq1FHtZdw5UWftH+z+tH2j/Z/Wq1FHtZdw5UWftH+z+tH2j/Z/Wq1FHtZdw5UWftH+z+tNedipCfK3YnnH4VBRR7WXcOVFLTtOYt9tveXPIB/ma36KK7DEKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAK13aRXkRjkH0PcGsrTlurJ5LablFwV/HPINb1Vrj+H8aio2o3RUVdh9o/2f1o+0f7P61Worm9rLuacqLP2j/Z/Wj7R/s/rVaij2su4cqLP2j/Z/Wj7R/s/rVaij2su4cqLP2j/AGf1o+0f7P61Woo9rLuHKiz9o/2f1o+0f7P61Woo9rLuHKiz9o/2f1o+0f7P61Woo9rLuHKi9HJ5meMYqSq1v/F+FWa6abbjdmclZhRRRVkhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH/9fpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKza0qza56/Q0phRRRXMaBRRRQAUUUUAFFFFABRRRQAUUUUAaVFFFeic4UUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFVrj+H8as1WuP4fxrOr8LKjuVqKKK4jYKKKKACiiigAooooAKKKKACiiigCzb/xfhVmq1v/ABfhVmu2l8KMZbhRRRWhIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//Q6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACs2tKs2uev0NKYUUdeBVlIO7/lWEYuWxbaRErqBgqDVsJGQCAOaibyY+CMmp1IKgjgV0wj0ZnJ9itIyIdoUGoCcnOMVaZ4txDD8aDCjDKnFRKDlsUnbcqUU50ZDg02sGrblhRRRSAKKKKANKiiivROcKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACq1x/D+NWarXH8P41nV+FlR3K1FFPSNn6dPWuNJvRG1xqnac4z9asxlHOCoBpfKjQZbn60qNGWwg/Gt4QcXqZt32FZY0UsVFVWcMMBQKuSFVXLDIqICGTgDBqpxu7IUX1ZVoqd4COV5qCueUWtzRO4UUUVIwooooAs2/wDF+FWarW/8X4VZrtpfCjGW4UUUVoSFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9HpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKza0qza56/Q0plm3UcuallfYvHU0y3+4frTLjqKafLTuhbyK9X4/uD6VQq/H9wfSoobsqexTl/1hp8LlW2noaZL/AKw01fvD61F7SuVbQvOodSKoVpVmnqa0rrZkQCiiiuc0CiiigDSooor0TnCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqtcfw/jVmq1x/D+NZ1fhZUdysOTitFQFGBWev3hWgenFZ0OrKmU5X3tjsKWD7/4VDU0H3/wrKLvJNlNWRNP/AKuqYOORVyf/AFdU6qt8QobF+Nt6g1WnXa2R3qW3+6frSXHQVpLWF2StJFWiiiuU1CiiigCzb/xfhVmq1v8AxfhVmu2l8KMZbhRRRWhIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB/9LpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKza0qza56/Q0pk8DhTtPep5U3rx1FUalWZl4PIqIVFblkNx1uiIgg4NX4/uD6VCZo2+8tWFxtGOBWlKKT0ZMn3KMv+sNSwxnO9vwp7SRoxyvNRtOx+6MVFop3bK1asiaWQKuB1NUqCSTk1NAuXz6VLk5yGlyoXy1Rd0n5ChUjkHy8GknOXx6UyM4cGm2lLltoLW1xpBU4NJVm4Xo34VWqJx5XYpO6NKiiiu4wCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqtcfw/jVmq1x/D+NZ1fhZUdytWgjh1yKz6VWZTlTXNTnys0lG5JLGVOR0NLB9/wDCni4/vCnxtGzfKMGtEouV4sTbtqE/+rqoqljgVecqFywyKh89QMKtOpFc12xRbtoTKoRcVUlfe3HQUjyM/XpTKidS6stiox6sVVLHC81YWAYyx/Kq1XIf9V+dFJJvUJNlOiiisSizb/xfhVmq1v8AxfhVmu2l8KMZbhRRRWhIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB/9PpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKza0qza56/Q0phRRRXMaEimIfeBJqfz09DVSitFUa2JcUywzxPyQc1AcZ+XpSUVMpX3GlYKsW/U1Xqe3PzEe1VS+JClsMm/1hpi/eH1qSYYkPvTEGWA96UviY1sWp/ufjVOrdwflA96qVVb4hQ2NKiiiuwxCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqtcfw/jVmq1x/D+NZ1fhZUdytRRRXEbCrtz82ce1WFkiT7oNVqKuMmthNXLZnjIwQagYxEfICDUdFOVRvcFGwUUUVmMKuQ/6r86p1ch/wBV+dbUfiInsU6KKKxLLNv/ABfhVmq1v/F+FWa7aXwoxluFFFFaEhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH//1OkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArNpuo6itmuxOZT0Hp7mpVjd1DAcHnnj+dYVk3axpBjKKk8mT0o8mT0rn5Jdi7ojoqTyZPSjyZPSjkl2C6I6Kk8mT0o8mT0o5JdguiOlVirBh2p/kyelHkyelNRl2C6JpFEqhk5IpsUZU734xUfkyelHkyelaa35uUnpa4SPvbPao6k8mT0o8mT0rNxk3dopNF6iiiu4wCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqtcfw/jVmoJkZ8bRnFZ1FeLsVHcqUVJ5MnpR5MnpXJyS7Gt0R0VJ5MnpR5MnpRyS7BdEdFSeTJ6UeTJ6UckuwXRHRUnkyelHkyelHJLsF0MAJOBVyMBU2kjNVvJk9KPJk9K0heOthOz6jWUr1ptSeTJ6UeTJ6VHI+w7olt/4vwqzWNLfLY3CRSj5W+8fT0PvWwrKyhlOQeQRXVTVoq5lLcWiiitCQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD//1ekooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACsvUdRWzXYnMp6D09zRqOorZrsTmU9B6e5qpp2nMW+23vLnkA/zNABp2nMW+23vLnkA/wAzW/RRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBWu7SK8iMcg+h7g1gW1zPpU/wBku+Yj0Pp7j2rqKrXdpFeRGOQfQ9waALCsrKGU5B5BFLXL21zPpU/2S75iPQ+nuPaunVlZQynIPIIoAWiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/W6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArL1HUVs12JzKeg9Pc0ajqK2a7E5lPQenuaqadpzFvtt7y55AP8zQAadpzFvtt7y55AP8AM1v0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBWu7SK8iMcg+h7g1gW1zPpU/wBku+Yj0Pp7j2rqKrXdpFeRGOQfQ9waALCsrKGU5B5BFLXL21zPpU/2S75iPQ+nuPaunVlZQynIPIIoAWiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9fpKKKKACiiigAooooAKKKKACiiigAooppdB1YfnQA6imebH/eFHmR/3h+dOzFdD6KAQelFIYUUUUAFFFFABRRRQAUUUUAFZeo6itmuxOZT0Hp7mjUdRWzXYnMp6D09zVTTtOYt9tveXPIB/maADTtOYt9tveXPIB/ma36KKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCtd2kV5EY5B9D3BrAtrmfSp/sl3zEeh9Pce1dRVa7tIryIxyD6HuDQBYVlZQynIPIIpa5e2uZ9Kn+yXfMR6H09x7V06srKGU5B5BFAC0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9DpKKKKACiiigAoopCQoyeBQAtNZlUZY4qpJddo/wA6qFixyxya0VN9TNz7F5rpRwgzVdriVu+PpUFFaKCRm5NjixPU5pKSiqJFopKKAFzUglkXoxqKiiwy4t0w+8M/SrCTRv0PPoay6Kh00ylNmzRWbHcOnB5HvV6OVJB8vX0rKUGjVSTJKKKKkoKy9R1FbNdicynoPT3NGo6itmuxOZT0Hp7mqmnacxb7be8ueQD/ADNABp2nMW+23vLnkA/zNb9FFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFa7tIryIxyD6HuDWBbXM+lT/ZLvmI9D6e49q6iqt3aRXkRjkH0PcGgCyrKyhlOQeQRS1y9tcz6VP8AZLvmI9D6e49q6dWVlDKcg8gigBaKKKACimGRB1YfnSedF/eFOzFdElFR+dF/eFOEiHow/OizC6HUUUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9HpKKKKACiiopZREuT1PQU0rg2LJKsQy34Cs2SVpDlunpTGdnbc3Wm1vGFjCUri0UlFWQLRSUUALRSUUALRSUUALRSUUALRSUUALSgkHI4NNooGaENyG+WTg+tVtR1FbNdicynoPT3NQVBZWcaXRmuG3nPy59fesZw6o1jPox+nacxb7be8ueQD/M1v0UVkaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUVVkuVXhOT69qaTewm0twvLWG6hMc3Ho3oaq2uyygECEyEcknp+FMZ2c5Y5ptaqn3MnU7FhriRuhx9KhLFupzTaK0SSIbbFopKKBC0UlFADwzL90kVKtxIvXn61XooaTGm0aCXKNw3FWQQRkc1jU9JHQ5U4rN0+xaqdzWoqtHcq3D8H9Ks1k01uap32CiiikMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/9LpKKKKAGSOsalmrId2kYs1SXEvmvx90dKgrohCyMZyuLRSUVoQLRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALRSUUAaNtPuHlv1HSrlYYJByOorXhkEqBu/esKkbao1hK+hLRRRWRoFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUjMqDcxwKR3VF3N0FZcsrStk9Owq4xuTKViSWdpOBwtV6SiuhK2xg3cWikooELRSUUALRSUUALRSUUALRSUUALRSUUALViK4aP5W5Wq1FJq+407G0rBhuU5BpayoZmiPqD1FaisHAZeQawlGxvGVxaKKKgoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/9PpKq3cuxNo6t/KrVYs8nmSlu3QVpTjdkTdkR0UlFdJiLRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALVi2l8uTB6NwarUUmrqw07G/RUNvJ5kQJ6jg1NXI1bQ6EFFFFIAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKYZEU4J5pNpbhYfRUfnR+tHnR+tLnj3HZklFR+dH60edH60c8e4WZJRUfnR+tHnR+tHPHuFmSUVH50frR50frRzx7hZklFR+dH60edH60c8e4WZJRUfnR+tHnR+tHPHuFmSUUgIYZHSlqhBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABQSAMmiqF3L/yyX8aqMbuwm7IhnmMrcfdHSoKSiulK2hzt3FopKKYC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC1Ygm8psH7p61WopNX0BOxu9eRRVK0myPKbt0q7XLJWdjoTurhRRRSGFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUU1nVPvHGab50frUuSW7HZklFR+dH60edH60c8e4WZJRUfnR+tHnR+tHPHuFmSUVH50frR50frRzx7hZklFR+dH60edH60c8e4WZJRUfnR+tHnR+tHPHuFmSUVH50frSiRGOAeaOZdwsz//U3p38uJm79B+NYlaV+2FVPU5rMrppLS5jN6i0UlFakC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAF+xfDlD3Ga06woG2TK3vW7XNVWtzaD0CiiisiwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKozf6w1eqjN/rDWNf4S4bkdFFFchqFFFFABRRRQAUUUUAFFFFABRRRQBeh/1YqSo4f8AVipK74fCjB7hRRRVCCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAZI4jQue1YpJYknqauXsmWEY7cmqNdNONlcxm9RaKSitCBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBysVYMOorbRxIgcd6wqv2UnWM/UVlVjdXLg9bGhRRRXObBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAVrj+H8arVZuP4fxqtXHV+Jm0dgooorIoKKKKACiiigAooooAKKKKACpIf9YKjqSH/WCqh8SE9j/9W9fHMwHoKpVYuz/pDfh/Kq1dkF7qMJbi0UlFWIWikooAWikooAWikqSNVc4dgoFJgMorSitraQZVi2OvaqU8XlSlByO1Sppuw3G2pFRWjFZLj98fmPYVVuY1hl2KcjFCmm7IHFrUgopKKsQtFJRQAtFJRQAtFJRQAtFJRQAtdEp3KG9Rmucrfg5hT/AHRWFZaIuBLRRRXOahRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVRm/1hq9VGb/WGsa/wlw3I6KKK5DUKKcpUfeGasIkTjIFXGHNsxN2KtFW2jiQZIquxQ/dGKcocu7BSuMooorMYUUUUAFFFFAF6H/VipKjh/1YqSu+Hwowe4UUUVQgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKhuG2QsfbH500ruwMx5H3uX9TTKSiu2xzi0UlFAhaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBalify5Ff0NQ0UmhnRUVFC2+JW9qlrjaOgKKKKQBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBWuP4fxqtVm4/h/Gq1cdX4mbR2CiilGM88isyhKKsIIXOMEGpTDGBkitFSb1TJcrFKipGMWMKDUdZtWKQUUUUgCiiigAqSH/AFgqOpIf9YKqHxIT2P/WsXf/AB8P+H8qrVZvRi4Y+uP5VVruhsjB7i0UlFUIWikooAWikooAWikooAv2D4lK/wB4fyq7OsaN9pfnaMAe9ZlorNOpXtyfpWjfLugz/dINc8176NI7GS8jO5djyaZnPJpKeiPI21Bk1vsZjaK0o7FQu6U546CsylGSew2rC0UlFUIWikooAWikooAWikooAWt+3/1CfQVz9dFCMQoD/dFYVtkXAkooormNQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKozf6w1eqjN/rDWNf4S4bkdPSNn6U1V3MF9a0AAowOgrGnT5tWXKViAQIBljT4/LyQlVpJC59qkt+prSMlzWiiWna7JpNmBvqPyY2GUNFx90VXVihyKJyXNZoIp20HPEydeRUdaIIZc9jVGRdjY7VFSnbVDjK+jGUUUViWFFFFAF6H/VipKjh/1YqSu+Hwowe4UUUVQgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKpXxxEB6mrtZ2oHhB9aun8SJlsZtFJRXYYi0UlFAC0UlFAC0UlFAC0U5FDNhmCj1NX4be1kyAxYj8KmUktxpXM6irF1CIXAXoRxU8FoGAaY4z0FLnVrhyu9ihRVq7hSFgE7jpVSqTuroTVhaKSimAtFJRQAtFJRQAtFJRQAtFJRQBs2TZgx6EirdULA/u2HvV+uOfxM2jsFFFFQUFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFa4/h/Gq1Wbj+H8arVx1fiZtHYVVLHAqwtv/AHj+VSxoEX3PWoZpDnYPxq1BRV5E8zbsh6iFXAXrUrY2nd0qlF/rBVyT/VmrhK8W7CktSIRwv901G8DLyORUIOORV6J965PUVnHlno0U7oo0VPOgB3DvUFZSjZ2KTuFFFFSMKkh/1gqOpIf9YKqHxIT2P//Xu6iuJFb1GPyrPrY1BN0If+6f0NY1dlJ3iYyWotFJRWhItFJRQAtFJRQAoyTgU7Y+7Zg5Pan28ixTLI3QVpS30IXMfzN246VEpNOyRSSIJWFrF5CH525Y1of6+2/3l/WufZizFmOSa0bS7jjj8uXjHQ1nODtdblRZUhhMpOTtVeSfSos4yAat3N0JB5cQwvU+9Uq1jd6shm3Z/wDHr+dYtbVn/wAev51iVFPeRUtkLRSUVqQLRSUUALRSUUALRSUUAOUFmCjqTit27tvtVs1vu27sc4z0OaybNN9wvoOfyrfrmrvVI1gc3/wj3/Tf/wAd/wDr0f8ACPf9N/8Ax3/69dJRWBZzf/CPf9N//Hf/AK9H/CPf9N//AB3/AOvXSUUAc3/wj3/Tf/x3/wCvR/wj3/Tf/wAd/wDr10lFAHN/8I9/03/8d/8Ar0f8I9/03/8AHf8A69dJRQBzf/CPf9N//Hf/AK9H/CPf9N//AB3/AOvXSUUAc3/wj3/Tf/x3/wCvR/wj3/Tf/wAd/wDr10lFAHN/8I9/03/8d/8Ar0f8I9/03/8AHf8A69dJRQBzf/CPf9N//Hf/AK9H/CPf9N//AB3/AOvXSUUAc3/wj3/Tf/x3/wCvR/wj3/Tf/wAd/wDr10lFAHN/8I9/03/8d/8Ar0f8I9/03/8AHf8A69dJRQBzf/CPf9N//Hf/AK9H/CPf9N//AB3/AOvXSUUAc3/wj3/Tf/x3/wCvR/wj3/Tf/wAd/wDr10lFAHN/8I9/03/8d/8Ar0f8I9/03/8AHf8A69dJRQBzf/CPf9N//Hf/AK9H/CPf9N//AB3/AOvXSUUAc3/wj3/Tf/x3/wCvV2G3+yRi33btvfGOvNa9UZv9Yaxr/CXDcIf9YKtycIfpVJG2sG9Kv8MPY1NHWLQ573M6rFv1NQuhQ4NTW/U1nTVpIqWw64+6Kq1auPuiqyqWOBRV+II7FyH/AFYqG4+8PpVlQEXHpVKR97Z7VrU0gkyY6u4yipY4i/PQVL9nHY1iqcmrotySKtFOdChwabUNW0YyjNo/2uQ3Hm7d3bbnpx61H/wj3/Tf/wAd/wDr10EP+rFSV3Q+FGD3Ob/4R7/pv/47/wDXo/4R7/pv/wCO/wD166SiqEc3/wAI9/03/wDHf/r0f8I9/wBN/wDx3/69dJRQBzf/AAj3/Tf/AMd/+vR/wj3/AE3/APHf/r10lFAHN/8ACPf9N/8Ax3/69H/CPf8ATf8A8d/+vXSUUAc3/wAI9/03/wDHf/r0f8I9/wBN/wDx3/69dJRQBzf/AAj3/Tf/AMd/+vR/wj3/AE3/APHf/r10lFAHN/8ACPf9N/8Ax3/69H/CPf8ATf8A8d/+vXSUUAc3/wAI9/03/wDHf/r0f8I9/wBN/wDx3/69dJRQBzf/AAj3/Tf/AMd/+vR/wj3/AE3/APHf/r10lFAHN/8ACPf9N/8Ax3/69H/CPf8ATf8A8d/+vXSUUAc3/wAI9/03/wDHf/r0f8I9/wBN/wDx3/69dJRQBzf/AAj3/Tf/AMd/+vWjqP8AB+P9K06z9QHyK3ocVpT+JEy2MqikorsMRaKSigBaKSigBaKSigBas2j7Z19+Kq1LCrPKoTrmpktGNbm1PHG2JJOic1jSytK5c/h7Vs3S74HHtn8qwKyorS5UxxJPJ5pKdHG0rhF6mtJbS2T5ZGy31xWkpqJKVzLorUlsF25hJz6GsrpxRGSlsDVhaKSirELRSUUALRSUUALRSUUANX+1t7fYvucf3fT3qT/iof8AOytXTx+6Y/7X9Kv1xVPiZvHY5v8A4qH/ADso/wCKh/zsrpKKgZzf/FQ/52Uf8VD/AJ2V0lFAHN/8VD/nZR/xUP8AnZXSUUAc3/xUP+dlH/FQ/wCdldJRQBzf/FQ/52Uf8VD/AJ2V0lFAHN/8VD/nZR/xUP8AnZXSUUAc3/xUP+dlH/FQ/wCdldJRQBzf/FQ/52Uf8VD/AJ2V0lFAHN/8VD/nZR/xUP8AnZXSUUAc3/xUP+dlH/FQ/wCdldJRQBzf/FQ/52Uf8VD/AJ2V0lFAHN/8VD/nZR/xUP8AnZXSUUAc3/xUP+dlH/FQ/wCdldJRQBzf/FQ/52Uf8VD/AJ2V0lFAGJb/ANo/N9v9tv3fx6VZqzcfw/jVauOr8TNo7GlWc3LHPrV6Ng6g1WmQq24dDWtXWKaJho7DIv8AWCrkn+rNU4v9YKuSf6s0qXwsJbooVYt+pqvV2JNi89TWdJNyuVN6CT/c/GqdTzvk7R2qJULnAoqu8tAjohtFWRAvTdzUUkRTnqKTpySuNSRHUkP+sFR1JD/rBUw+JA9j/9DoZEEkbIe4xXMkFSVPUV1NYd/F5cvmDo/863oS1sRNdSlRTaK6jIdRTaKAHUU2igB1FNooAdRTaKAHUU2nojSHagyaBm1Zf8ev51iVv20flQCNiM85/GsSSGSL7449axptczKktER0U2itiB1FNooAdRTaKAHUU2nKpdgq9ScUDNbTo8K0p78CtOmRRiKNYx2FPrgnK7ubJWQUUUVIwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKozf6w1eqjN/rDWNf4S4bkdSJKycDkVHRXKm1qjVot+dGwwwp0fl5JjqooU/eOKso8KDANdEJ3d5GbXYfJswN/So/NiQYQUrPE4wTVdgg+6c0TnZ3jYIruK8rPx0FR0UVztt6s0SJpH/gXoKYjlDkUynIu5gtVzNu4rKxanA2Z96p1YnfJ2DtVeqqu8hQ2L0P+rFSVHD/qxUldUPhRk9woooqhBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVTvl3W5P8AdINXKZInmRsnqMVUXZpiexzdFJ0oruMBaKSigBaKSigBaKSgHBzQA4qynBBGav8A/HnD/wBNX/QVZe+t9uR8x7DFZEkjSuXfqazV5bovRbG5at5luueeMGshIHeYxDseT6VPZ3SQgpJ0PINOubxWBSEY3dT61CUlJpIbs0RRyJbrJsbLHhT7etVM55NJRWyjYi5safIzIyHnbjH41nXGPPfHqavW5FrbGZ+rdB/KsokkknqazgvebRT2SFopKK1IFopKKAFopKKAFopKACxAHU0Ab1mu23X35q1TUUIoQdAMU6uCTu7m6CiiikMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAK1x/D+NVqs3H8P41Wrjq/EzaOw5XZDlasCdSMMKq0owTycCpjNrRDcUy0vklgV61K2Np3dKrp5KHO7JqUyxEYJrpjJW1sZtajA8Kfdpjzs3C8U1lixlW/CoqwlN7FqK3Cnh9qbV6nrTKKzTsUFW5D+556nFMjiXOWIPsKdOhPzA9O1bRi1FshtNoq1JD/rBUdSQ/6wVlD4kU9j//0ekqC4hE8RTv1H1qeimnbVAcoQVJB4IpK1tQtv8Al4Qf73+NZFd8JcyuYtWFopKKoQtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtFJRQAtaunQZJnbtwtULeFriQIOnc+grpFVUUIowBwKwrTsuVFxXUdRRRXIaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFUZv9YavVRm/1hrGv8JcNyOiiiuQ1CiiigAooooAKKKKADrwKn4hX/aP6VJHEVG4/e/lTTASclq3VOSV0tSHJMrUVZ8oRguxziq1Zyi1uUncvQ/6sVJUcP+rFSV2Q+FGL3CiiiqEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBgXkflzt6NyPxqrW1fxb4vMHVP5Vh1205XiYyVmOoptFaEjqKbRQA6im0UAOoptFADqKbRQA6rdvCpHnzcRr+pplrCsr5kYBR1561pzQwTYBkwq9ACMVlOdtC0uplTztO+48AdB6VD71q/YrX/np+oqpeMgZYYvuoP1NOMk9Iia6sq0U2itCR1FNooAdRTaKAHVcsY/MnBPRef8Ko1vWMXlw7j1fn8O1Z1ZWiVFXZdoooriNgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAK1x/D+NVqs3H8P41Wrjq/EzaOwUUUVkUFFFFABRRRQAUUVMkJddwNUot7A3Yhq5E26M7u3FVvLfOMGpSRFHs/iNaU7xbbJlqV6kh/wBYKjqSH/WCs4fEhvY//9LpKKKKAAgEYPSufvLUwNvT7h/T2roKRlV1KsMg1pTm4sTVzkqKu3dm1ud6cp/L61Rrui01dGTQtFJRTELRSUUALRSUUALRSUUALRSUUALRSUUALRSUUALT40eVwiDJNEUbzOEjGSa6G1tUtl9WPU1nUqKKKUbjre3W3j2jknqfWrFFFcLd3dmoUUUUgCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKqyRuzkgcVaoqZRUlZjTsUfJk9KPJk9KvUVn7CJXOyj5MnpR5MnpV6ij2EQ52UfJk9KPJk9KvUUewiHOyj5MnpR5MnpV6ij2EQ52UvKl9P1o8qX0/WrtFHsUHOyl5Uvp+tJ5MnpV6ij2MQ52MjBVAD1p9FFapWViGFFFFMAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAAgEYNc3cwmCUr2PI+ldJVa6txcR4/iHINa0p8rJkrnOUUEFSVbgikrtMhaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSigBaKSnKrOwVRknpQBZtIPPlAP3Rya6Kq9tALeMJ3PJPvViuGpPmZrFWCiiisygooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAIJkZ8bRnFQeTJ6VeorKVJN3ZSk1oUfJk9KPJk9KvUUvYRHzso+TJ6UeTJ6Veoo9hEOdlHyZPSjyZPSr1FHsIhzso+TJ6U4RzDpkfjVyij2KDnZU2T+/50zyZPSr1FHsV3DnZR8mT0qSON1cEjirVFNUUncHNn//T6SiiigAooooACARg8g1j3WndZLf/AL5/wrYoq4zcXdCaucgQVOGGCKSuontYbgfvBz6jrWPNp00fMfzj26/lXXCtF7mbizPooIKnDDBFJWxItFJRQAtFJRQAtFJRQAtFJViG1nn+4vHqeBSbS3GQVbtrOW4Ofur6n+lacGmxR/NL85/StLpwK5p1+kSlHuQwwRwLtjH1Pc1NRRXM3fVmgUUUUgCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAM2+tPNHnRD5h1HrWHXXVmXlj5mZYR83cetdNKrb3WRKPVGJRSHIODwRRXUZi0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlFAC0UlKAWOAMk0AHXgVvWVp5I8yQfOf0ptnZCLEsvL9h6VpVyVat/dRpGPVhRRRXOWFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH/1OkooooAKKKKACiiigAooooAjkhilGJFDfWqEmlwNzGSv6itOiqjOS2YmjBfSph9xlI9+KgOn3YP3M/QiulorVV5C5Ucx9hu/wDnmfzFL9guz/B+o/xrpqKf1iXYORHPLplyeu1fqf8ACrSaSv8Ay0cn6DFa9FS68mHKirHZ20XKoCfU81aoorJtvcoKKKKQBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFO5so7j5h8r+v+NYE0EsDbZBj0PY11dNdFkXa4BB7GtqdZx0ZLjc5GitmfSwfmgOPY/41lSwywnEikfyrrjUjLYzaaI6KSirELRSUUALRSUUALRSUUALRUkUE0xxGpPv2/OtaDS1HzTnPsOn51EqkY7jSbMuG3luGxGPqewrftrOO3GfvN6/4VaVVQbUAAHYUtclSq5aGijYKKKKxKCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//V6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKCARg8iiigCnJYWsnO3af9nj/wCtVN9JH/LOT8CK2KK0VWS2YrI546XcjoVP41GdPu/7n6j/ABrpaKtYiQuVHNDT7v8AufqP8alGl3J6lR+P/wBaugooeIkHKjHTSR/y0k/IVcjsLaP+HcfVuf8A61XKKh1ZPdjsgAA4FFFFZjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/jpeg": {
       "width": 480
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A factor graph (e.g. a pose graph)\n",
    "from IPython.display import Image\n",
    "Image('img/simple-factor-graph.jpg', width=480)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-commission",
   "metadata": {},
   "source": [
    "Most of SLAM algorithms use probability distributions, e.g. Gaussian distribution, as factor potentials $\\Phi$. For example, \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}}\\prod_{i=0}^3 \\Phi_i\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}}\\phi_0(z_0; x_0, x_1)\\phi_1(z_1; x_0, x_2)\\phi_2(z_2; x_1, x_2)\\phi_3(z_3; x_2) \\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}} p_0(z_0; x_0, x_1)p_1(z_1; x_0, x_2)p_2(z_2; x_1, x_2)p_3(z_3; x_2) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-dynamics",
   "metadata": {},
   "source": [
    "The formulation above can also be viewed as a MLE.\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x_0,x_1,x_2,z_0,z_1,z_2,z_3) =& p(x_1,x_2,z_0,z_1,z_2,z_3|x_0) p(x_0) \\\\\n",
    "=& p(x_2,z_0,z_1,z_2,z_3|x_1,x_0)p(x_1|x_0)p(x_0)\\\\\n",
    "=& p(z_0,z_1,z_2,z_3|x_2, x_1,x_0)p(x_2|x_1, x_0)p(x_1)p(x_0)\\\\\n",
    "=& p(z_1,z_2,z_3|z_0, x_2, x_1, x_0) p(z_0 | x_2, x_1, x_0)p(x_2)p(x_1)p(x_0)\\\\\n",
    "=& p(z_1,z_2,z_3|z_0, x_2, x_1, x_0) p(z_0 |x_1, x_0)p(x_2)p(x_1)p(x_0) \\\\\n",
    "=& p_0(z_0| x_0, x_1)p_1(z_1| x_0, x_2)p_2(z_2| x_1, x_2)p_3(z_3| x_2)p(x_2)p(x_1)p(x_0)\\\\\n",
    "p(x_0,x_1,x_2,z_0,z_1,z_2,z_3) \\propto& p_0(z_0| x_0, x_1)p_1(z_1| x_0, x_2)p_2(z_2| x_1, x_2)p_3(z_3| x_2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}}p(x_0,x_1,x_2,z_0,z_1,z_2,z_3)\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}}p_0(z_0| x_0, x_1)p_1(z_1| x_0, x_2)p_2(z_2| x_1, x_2)p_3(z_3| x_2) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-court",
   "metadata": {},
   "source": [
    "If we assume the factor potentials are Gaussian distribution whose mean is the residual between observation and prediction based on potential function, then the factor graph can be converted to be a least square problem. For converting non-Gaussian distribution into least square problems, see [Mixture models for least square optimization]({% post_url 2021-05-11-paper-reading-mixture-models-for-least-square-optimization %}).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}}\\prod_{i=0}^3 \\Phi_i\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}}\\phi_0(z_0; x_0, x_1)\\phi_1(z_1; x_0, x_2)\\phi_2(z_2; x_1, x_2)\\phi_3(z_3; x_2) \\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}} p_0(z_0; x_0, x_1)p_1(z_1; x_0, x_2)p_2(z_2; x_1, x_2)p_3(z_3; x_2) \\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}} \\mathcal{N}(z_0-f_0(x_0, x_1), \\Sigma_0)\n",
    "\\mathcal{N}(z_1-f_1(x_0, x_2), \\Sigma_1) \\mathcal{N}(z_2-f_2(x_1, x_2), \\Sigma_2)\\mathcal{N}(z_3-f_3(x_2), \\Sigma_3)\\\\\n",
    "\\propto& \\underset{X}{\\operatorname{argmax}} log(\\mathcal{N}(z_0-f_0(x_0, x_1), \\Sigma_0)\n",
    "\\mathcal{N}(z_1-f_1(x_0, x_2), \\Sigma_1) \\mathcal{N}(z_2-f_2(x_1, x_2), \\Sigma_2)\\mathcal{N}(z_3-f_3(x_2), \\Sigma_3)\\\\\n",
    "=& \\underset{X}{\\operatorname{argmax}} \\|z_0-f_0(x_0, x_1)\\|^2_{\\Sigma_0} + \\|z_1-f_1(x_0, x_2)\\|^2_{\\Sigma_1} + \\|z_2-f_2(x_1, x_2)\\|^2_{\\Sigma_2} + \\|z_3-f_3(x_2)\\|^2_{\\Sigma_3}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-melissa",
   "metadata": {},
   "source": [
    "## Gauss-Newton Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-hotel",
   "metadata": {},
   "source": [
    "Gauss-Newton is an iterative optimization method which tries approaching the minima (maybe a local minima) step by step. It linearize the non-linear functions $f$ based on first-order Taylor expansion.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}} \\|z_0-f_0(x_0, x_1)\\|^2_{\\Sigma_0} + \\|z_1-f_1(x_0, x_2)\\|^2_{\\Sigma_1} + \\|z_2-f_2(x_0, x_1)\\|^2_{\\Sigma_2} + \\|z_3-f_3(x_2)\\|^2_{\\Sigma_3}\\\\\n",
    "=& \\|z_0-f_0(\\mu_0, \\mu_1) - J_0 \\Delta_{x_0, x_1}\\|^2_{\\Sigma_0} + \n",
    "\\|z_1-f_0(\\mu_0, \\mu_2) - J_1 \\Delta_{x_0, x_1}\\|^2_{\\Sigma_1} + \n",
    "\\|z_2-f_0(\\mu_0, \\mu_1) - J_2 \\Delta_{x_1, x_2}\\|^2_{\\Sigma_2} + \n",
    "\\|z_3-f_0(\\mu_0, \\mu_1) - J_3 \\Delta_{x_3}\\|^2_{\\Sigma_3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where $J$ is a jacobian matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-expression",
   "metadata": {},
   "source": [
    "The above equation can be written into a more compact matrix form:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{X} =& \\underset{X}{\\operatorname{argmax}} \\|J\\Delta_X - r\\|_{\\Sigma}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "J is normally a tall rectangular matrix. And the number of rows of J is equal to the number of measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-winter",
   "metadata": {},
   "source": [
    "Without considering the numeric stability, the above linear optimization problem is usually solved using Cholesky decomposition on $J^T \\Sigma J$.  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J^T \\Sigma^{-1} J \\hat{X} = J^T\\Sigma^{-1} r\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-medicaid",
   "metadata": {},
   "source": [
    "In practice, $A = J^T \\Sigma J$ and $b = J^T\\Sigma r$ are generated based on local blocks. And $J^T \\Sigma J$ is usually a sparse matrix in SLAM problems. \n",
    "\n",
    "$A$ is a square matrix which has the same number of rows as the number of node states. So in the toy example above, if $x \\in \\mathbb{R}^k$, then $A$ has $3 \\times k$ rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-restaurant",
   "metadata": {},
   "source": [
    "The block $\\|z_0-f_0(\\mu_0, \\mu_1) - J_0 \\Delta_{x_0, x_1}\\|^2_{\\Sigma_0}$ will give non-zeros fillings for rows and columns corresponding to state $x_0$ and $x_1$. if $z_0 \\in \\mathbb{R}^l $, then $J_0$ is a $l \\times 2k$ matrix. $J_0^T \\Sigma_0 J_0$ will be $2k \\times 2k$ which will be filled into rows and columns corresponding to state $x_0$ and $x_1$. If you would want to break it down further:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} J_{x_0}^T \\\\ J_{x_1}^T \\end{bmatrix} \\Sigma^{-1} \\begin{bmatrix} J_{x_0}, J_{x_1} \\end{bmatrix} \\hat{X} = \\begin{bmatrix} J_{x_0}^T \\\\ J_{x_1}^T \\end{bmatrix} \\Sigma^{-1} r\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-lewis",
   "metadata": {},
   "source": [
    "## Cholesky Factorization\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Ax = b \\\\\n",
    "R^T Rx = b\n",
    "\\end{align}\n",
    "$$\n",
    "$R$ is a upper triangular matrix. Then $R^{T}Rx = b$ will be solved in two steps: 1)\n",
    "solve the lower triangular system $R^{T}y = b$; 2) solve the upper triangular\n",
    "system $Rx = y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-deployment",
   "metadata": {},
   "source": [
    "Given a $3 \\times 3$ matrix $A$ factorized to be $R^{T}R$:\n",
    "$$\n",
    "\\begin{align}\n",
    "A = R^{T}R & =\n",
    "\\left[\\begin{matrix}   R_{11} & 0 & 0 \\\\\n",
    "   R_{12} & R_{22} & 0 \\\\\n",
    "   R_{13} & R_{23} & R_{33}\\\\\n",
    "\\end{matrix}\\right]\n",
    "\\left[\\begin{matrix}   R_{11} & R_{12} & R_{13} \\\\\n",
    "   0 & R_{22} & R_{23} \\\\\n",
    "   0 & 0 & R_{33}\n",
    "\\end{matrix} \\right]\\\\\n",
    "& =\n",
    "\\left[\\begin{matrix}   R_{11}^2 &  R_{11}R_{12} & R_{11}R_{13}  \\\\\n",
    "   R_{12}R_{11} & R_{12}^2 + R_{22}^2&  R_{12}R_{13}+R_{22}R_{23} \\\\\n",
    "   R_{13}R_{11} & R_{13}R_{12}+R_{23}R_{22} & R_{13}^2 + R_{23}^2+R_{33}^2\n",
    "\\end{matrix}\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-auditor",
   "metadata": {},
   "source": [
    "We obtain the following:\n",
    "\n",
    "\\begin{align}\n",
    "R =\n",
    "\\left[\\begin{matrix} \\sqrt{A_{11}} &  \\frac{A_{12}}{R_{11}} & \\frac{A_{13}}{R_{11}}  \\\\\n",
    "0 & \\sqrt{A_{22} - R_{12}^2} & \\frac{ A_{23} - R_{12}R_{13}}{R_{22}} \\\\\n",
    "0 & 0   & \\sqrt{A_{33}- R_{13}^2 - R_{23}^2}\n",
    "\\end{matrix}\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-spring",
   "metadata": {},
   "source": [
    "Therefore we can get following formulae for the entries of $R$ ($i$ is row index\n",
    "and $j$ is the column index). The whole Cholesky decomposition process is done row by row.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "R_{i,i} &= \\sqrt{ A_{i,i} - \\sum_{k=1}^{i-1} R_{k,i}^2 } \\\\\n",
    "R_{i,j} &= \\frac{1}{R_{i,i}} \\left( A_{i,j} - \\sum_{k=1}^{i-1} R_{k,i} R_{k,j} \\right) \\quad j > i.\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Another way to think about Cholesky decomposition is that a non-zero element at row $i$ column $j$ ($j > i$) will contribute a non-zeros fillings to row $j$ later.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "R_{i,i} &= \\sqrt{ A_{i,i} - \\sum_{k=1}^{i-1} R_{k,i}^2 } \\\\\n",
    "R_{i,j:} &= \\frac{1}{R_{i,j:}} \\left( A_{i,j} - \\sum_{k=1}^{i-1} R_{k,i} R_{k,j:} \\right) \\quad j > i.\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beautiful-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve linear equation using numpy linear solver: \n",
      " [-0.13043478  2.          0.32608696]\n",
      "Cholesky Decomposition: \n",
      " [[1.        0.5       0.4      ]\n",
      " [0.        0.8660254 0.       ]\n",
      " [0.        0.        1.356466 ]]\n",
      " \n",
      " \n",
      "Solution x impl: \n",
      " [-0.13043478  2.          0.32608696]\n",
      "Cholesky Decomposition impl: \n",
      " [[1.        0.5       0.4      ]\n",
      " [0.        0.8660254 0.       ]\n",
      " [0.        0.        1.356466 ]]\n"
     ]
    }
   ],
   "source": [
    "# Cholesky decomposition\n",
    "\n",
    "import numpy as np\n",
    "A = np.array([[1, 0.5, 0.4],\n",
    "              [0.5, 1, 0.2],\n",
    "              [0.4, 0.2, 2]])\n",
    "b = np.array([1,2,1])\n",
    "x = np.linalg.solve(A, b)\n",
    "L = np.linalg.cholesky(A)\n",
    "print(f'Solve linear equation using numpy linear solver: \\n {x}')\n",
    "print(f'Cholesky Decomposition: \\n {L.T}')\n",
    "\n",
    "def Cholesky(A):\n",
    "    nrows, ncols = A.shape\n",
    "    assert(nrows == ncols)\n",
    "    R = np.zeros(A.shape)\n",
    "    for i in range(nrows):\n",
    "        R[i, i:] = A[i, i:]\n",
    "        \n",
    "    for i in range(nrows):\n",
    "        row_i = R[i, :]\n",
    "        d = row_i[i]\n",
    "        d = np.sqrt(d)\n",
    "        row_i /= d\n",
    "        for j in range(i+1, ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            row_j = R[j, :]\n",
    "            row_j[j:] -= s*row_i[j:]\n",
    "    return R\n",
    "\n",
    "\n",
    "def SolveUpperTriangular(R, y):\n",
    "    nrows, ncols = R.shape\n",
    "    x = np.zeros(y.shape).reshape(nrows)\n",
    "    for inv_i in range(0, nrows):\n",
    "        i = nrows - inv_i - 1\n",
    "        row_i = R[i, :]\n",
    "        y_i = y[i]\n",
    "        for j in range(i+1, nrows):\n",
    "            y_i -= x[j]*row_i[j]\n",
    "        x[i] = y_i / row_i[i]\n",
    "    return x\n",
    "        \n",
    "    \n",
    "def SolveLowerTriangular(R, b):\n",
    "    nrows, ncols = R.shape\n",
    "    y = np.zeros(nrows)\n",
    "    y[:] = b[:]\n",
    "    for i in range(0, nrows):\n",
    "        row_i = R[i, :]\n",
    "        y[i] /= row_i[i]\n",
    "        for j in range(i+1, ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            y[j] -= y[i]*s\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "R = Cholesky(A)\n",
    "y = SolveLowerTriangular(R, b)\n",
    "\n",
    "x = SolveUpperTriangular(R, y)\n",
    "print(f' \\n \\nSolution x impl: \\n {x}')\n",
    "print(f'Cholesky Decomposition impl: \\n {R}')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8edf23-be72-4a53-a607-a6e1c5441d48",
   "metadata": {},
   "source": [
    "## Covariance and Factor Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d344d3-1ca7-44c5-a2ac-94666a1b39f3",
   "metadata": {},
   "source": [
    "We have \n",
    "$$\n",
    "\\begin{align}\n",
    "A \\Delta x = b \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Where $A = J^T \\Sigma^{-1} J$ and $b = J^T \\Sigma^{-1} r$. So the uncertianty of the solution $\\Delta x$ is $A^{-1}$.\n",
    "\n",
    "Among many measurements, how do we know which one affect a particular state most? \n",
    "\n",
    "From above, we have:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta x = A^{-1} * J^T * \\Sigma^{-1} * r \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "then assume we have $n$ states and $m$ measurements:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "\\Delta X_0 \\\\\n",
    "\\vdots \\\\\n",
    "\\Delta X_n\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\Sigma_{X_0,X_0} & \\cdots & \\Sigma_{X_n0, X_n} \\\\\n",
    "\\vdots & \\cdots & \\vdots \\\\\n",
    "\\Sigma_{X_n,X_0} & \\cdots & \\Sigma_{X_n, X_n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "J^{z_0}_{x_0} & \\cdots & J^{z_m}_{x_n} \\\\\n",
    "\\vdots & \\cdots & \\vdots \\\\\n",
    "J^{z_m}_{x_0} & \\cdots & J^{z_m}_{x_n}\n",
    "\\end{bmatrix} ^T\n",
    "\\begin{bmatrix}\n",
    "\\Sigma^{-1}_{z_0}, 0, \\cdots, 0 \\\\\n",
    "0, \\Sigma^{-1}_{z_1}, \\cdots, 0 \\\\\n",
    "\\vdots, \\cdots , \\cdots, \\vdots \\\\\n",
    "0, \\cdots, 0, \\Sigma^{-1}_{z_n}\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "r_0 \\\\\n",
    "\\vdots \\\\\n",
    "r_m \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now, the constribution of $z_0$ towards $\\Delta_X$ can be calculated as $ (\\Sigma_{X_n, X_0}J_{x_0}^{z_0} + \\cdots + \\Sigma_{X_n, X_n}J_{x_n}^{z_0})*(\\Sigma^{-1}_{z_0}r_0)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44c5a01c-bd15-4a72-bdfc-a17753eaa0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=array([[112.]])\n",
      "[[0.00892857]]\n",
      "b=array([[-9.37]])\n",
      "[[-0.08366071]]=\n",
      "new_x=array([[-0.08366071]])\n",
      "c0=0.0009, c1=0.0125, c2=-0.0982, c3=0.0012\n",
      "c0 + c1 + c2 + c3=-0.0837\n",
      "delta_x.item()=-0.0837\n"
     ]
    }
   ],
   "source": [
    "# Covariance and factor contribution\n",
    "\n",
    "import numpy as np\n",
    "# Robot position\n",
    "x = 0 \n",
    "\n",
    "# Robot position measurements and variance\n",
    "\n",
    "z0 = 0.1\n",
    "s0 = 1\n",
    "r0 = z0 - x\n",
    "\n",
    "z1 = 0.14\n",
    "s1 = 0.1\n",
    "r1 = z1 - x\n",
    "\n",
    "z2 = -0.11\n",
    "s2 = 0.01\n",
    "r2 = z2 - x\n",
    "\n",
    "z3 = 0.13\n",
    "s3 = 1\n",
    "r3 = z3 - x\n",
    "\n",
    "J = np.array([1, 1, 1, 1]).reshape(4, 1)\n",
    "J_transpose = J.T\n",
    "S = np.diag([1.0/s0, 1.0/s1, 1.0/s2, 1.0/s3])\n",
    "r = np.array([r0, r1, r2, r3]).reshape(4, 1)\n",
    "\n",
    "A = J_transpose.dot(S).dot(J)\n",
    "print(f\"{A=}\")\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(f\"{A_inv}\")\n",
    "b = J_transpose.dot(S).dot(r)\n",
    "print(f\"{b=}\")\n",
    "\n",
    "delta_x = A_inv.dot(b)\n",
    "print(f\"{A_inv.dot(b)}=\")\n",
    "\n",
    "new_x = x + delta_x\n",
    "print(f\"{new_x=}\")\n",
    "\n",
    "# r0 contribution to x\n",
    "c0 = A_inv[0, :] @ J_transpose[:, 0] * S[0, 0] * r0\n",
    "\n",
    "c1 = A_inv[0, :] @ J_transpose[:, 1] * S[1, 1] * r1\n",
    "c2 = A_inv[0, :] @ J_transpose[:, 2] * S[2, 2] * r2\n",
    "c3 = A_inv[0, :] @ J_transpose[:, 3] * S[3, 3] * r3\n",
    "\n",
    "print(f\"{c0=:.4f}, {c1=:.4f}, {c2=:.4f}, {c3=:.4f}\")\n",
    "\n",
    "print(f\"{c0 + c1 + c2 + c3=:.4f}\")\n",
    "print(f\"{delta_x.item()=:.4f}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-pollution",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Incremental Cholesky Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-fleet",
   "metadata": {},
   "source": [
    "If you follows the Cholesky factorization described from above section, you may notice that we could easily reconstruct $R$ in intermediate steps. Mathematically, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  A =\n",
    "  \\begin{bmatrix}\n",
    "    A_{00} & A_{01} \\\\\n",
    "    A_{10} & A_{11}\n",
    "  \\end{bmatrix} \\\\\n",
    "  R =\n",
    "  \\begin{bmatrix}\n",
    "    R_{00} & R_{01} \\\\\n",
    "    \\textbf{0} & R_{11}\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-china",
   "metadata": {},
   "source": [
    "An intermediate matrix $R^{in}$ of the decomposition process has the form\n",
    "$$\n",
    "\\begin{align}\n",
    "  R^{in} =\n",
    "  \\begin{bmatrix}\n",
    "    R_{00} & R_{01} \\\\\n",
    "    \\textbf{0} & A_{11}^{in}\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "where $A_{11}^{in}$ is the filled-in version of submatrix $A_{11}$ resulting\n",
    "from the partial factorization. Given the completed factorization $R$, we can\n",
    "compute $A_{11}^{in}$ as\n",
    "$$\n",
    "\\begin{align}\n",
    "  A_{11}^{in}=R_{11}^T R_{11}\n",
    "\\end{align}\n",
    "$$\n",
    "This in turn allows us to reconstruct the intermediate matrix $R^{in}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-liquid",
   "metadata": {},
   "source": [
    "Let $\\tilde{A}$ be the evolved version of $A$ following the addition of new\n",
    "information. This update only affects a portion $A_{11}$ of the information\n",
    "matrix, with corresponding effects to $R_{11}$ in the factorization. That is,\n",
    "the new information matrix $\\tilde{A}$ and its factorization matrix $\\tilde{R}$\n",
    "have the forms:\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\label{aprilsam:eq:updated-information-factorization-forms}\n",
    "  \\tilde{A} =\n",
    "  \\begin{bmatrix}\n",
    "    A_{00} & A_{01} \\\\\n",
    "    A_{10} & A_{11} + A_{new}\n",
    "  \\end{bmatrix} \\ \\\n",
    "  \\tilde{R}=\n",
    "  \\begin{bmatrix}\n",
    "    R_{00} & R_{01} \\\\\n",
    "    \\textbf{0} & \\tilde{R}_{11}\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "Because $\\tilde{A}=\\tilde{R}^T\\tilde{R}$, we can express the updated portion of\n",
    "the information matrix as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\tilde{R}_{11}^T\\tilde{R}_{11} = A_{11}^{in} + A_{new}\n",
    "\\end{align}\n",
    "$$\n",
    "Then we can do a reconstruction following with a Cholesky decomposition.\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\tilde{R}_{11}^T\\tilde{R}_{11} &= R_{11}^TR_{11} + A_{new}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-certificate",
   "metadata": {},
   "source": [
    "**Note: This incremental process assumes that the linearization points stay the same.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "human-coast",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original A: \n",
      " [[1.  0.5 0.4]\n",
      " [0.5 1.  0.2]\n",
      " [0.4 0.2 2. ]]\n",
      "Reconstructed A: \n",
      " [[1.  0.5 0.4]\n",
      " [0.  1.  0.2]\n",
      " [0.  0.  2. ]] \n",
      "\n",
      "original R: \n",
      " [[1.        0.5       0.4      ]\n",
      " [0.        0.8660254 0.       ]\n",
      " [0.        0.        1.356466 ]]\n",
      "Inc R: \n",
      " [[1.        0.5       0.4      ]\n",
      " [0.        0.8660254 0.       ]\n",
      " [0.        0.        1.356466 ]]\n",
      "original y: \n",
      " [1.         1.73205081 0.44232587]\n",
      "Inc y: \n",
      " [1.         1.73205081 0.44232587]\n"
     ]
    }
   ],
   "source": [
    "# Incremental Cholesky Decomposition\n",
    "\n",
    "def CholeskyReconstructA(R_, stop_row_id):\n",
    "    R = R_.copy()\n",
    "    nrows, ncols = R.shape\n",
    "    for i in range(nrows-1, stop_row_id-1, -1):\n",
    "        row_i = R[i, :]\n",
    "        d = row_i[i]\n",
    "        for j in range(ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            if j > i:\n",
    "                row_j = R[j, :]\n",
    "                row_j[j:] += s*row_i[j:]\n",
    "        row_i[i] *= d\n",
    "    return R\n",
    "\n",
    "def CholeskyInc(R_, start_row_id):\n",
    "    nrows, ncols = R_.shape\n",
    "    assert(nrows == ncols)\n",
    "    R = R_.copy()\n",
    "    for i in range(start_row_id, nrows):\n",
    "        row_i = R[i, :]\n",
    "        d = row_i[i]\n",
    "        d = np.sqrt(d)\n",
    "        row_i /= d\n",
    "        for j in range(ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            if j > i:\n",
    "                row_j = R[j, :]\n",
    "                row_j[j:] -= s*row_i[j:]\n",
    "    return R\n",
    "\n",
    "def CholeskyReconstruct_y(R, y_, stop_row_id):\n",
    "    nrows, ncols = R.shape\n",
    "    y = np.zeros(nrows)\n",
    "    y = y_.copy()\n",
    "    for i in range(nrows-1, stop_row_id-1, -1):\n",
    "        row_i = R[i, :]\n",
    "        for j in range(i+1, ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            y[j] += y[i]*s\n",
    "        y[i] *= row_i[i]\n",
    "    return y\n",
    "\n",
    "def SolveLowerTriangularInc(R, y_, start_row_id):\n",
    "    nrows, ncols = R.shape\n",
    "    y = y_.copy()\n",
    "    for i in range(start_row_id, nrows):\n",
    "        row_i = R[i, :]\n",
    "        y[i] /= row_i[i]\n",
    "        for j in range(i+1, ncols):\n",
    "            s = row_i[j]\n",
    "            if s == 0:\n",
    "                continue\n",
    "            y[j] -= y[i]*s\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "print(f'original A: \\n {A}')\n",
    "R = Cholesky(A)\n",
    "reconstruct_A = CholeskyReconstructA(R, 0)\n",
    "print(f'Reconstructed A: \\n {reconstruct_A} \\n')\n",
    "\n",
    "print(f'original R: \\n {R}')\n",
    "test_row_id = 2\n",
    "reconstruct_partial_A = CholeskyReconstructA(R, test_row_id)\n",
    "inc_R = CholeskyInc(reconstruct_partial_A, test_row_id)\n",
    "print(f'Inc R: \\n {inc_R}')\n",
    "\n",
    "print(f'original y: \\n {y}')\n",
    "test_row_id = 2\n",
    "reconstruct_partial_y = CholeskyReconstruct_y(R, y, test_row_id)\n",
    "inc_y = SolveLowerTriangularInc(R, reconstruct_partial_y, test_row_id)\n",
    "print(f'Inc y: \\n {inc_y}')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-invite",
   "metadata": {},
   "source": [
    "## Incremental Smoothing and Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-essex",
   "metadata": {},
   "source": [
    "### Variable Ordering for Cholesky Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-anthony",
   "metadata": {},
   "source": [
    "### Incremental Mapping for Odometry Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-first",
   "metadata": {},
   "source": [
    "### Incremental Mapping for Loop Closure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-avatar",
   "metadata": {},
   "source": [
    "### iSAM, iSAM2 and AprilSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-marks",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "1. Wang, High Availability Mapping and Localization\n",
    "2. Dellaert, Factor Graphs for Robot Perception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "185.6666717529297px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
