---
layout: notebook
title: Machine Learning Notes - Pytorch
description: Machine Learning Notes - pytorch basics
tag: ML
---

<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="A-List-of-Related-Posts">
    A List of Related Posts
    <a class="anchor-link" href="#A-List-of-Related-Posts">
     ¶
    </a>
   </h2>
   <ol>
    <li>
     <a href="{% post_url 2021-05-04-machine-learning-pytorch %}">
      Pytorch(this)
     </a>
    </li>
    <li>
     <a href="{% post_url 2021-05-07-machine-learning-loss %}">
      Loss function
     </a>
    </li>
    <li>
     <a href="{% post_url 2021-05-07-machine-learning-backpropagation %}">
      Backpropagation
     </a>
    </li>
    <li>
     <a href="{% post_url 2021-05-13-machine-learning-gradient-descent %}">
      Gradient Descent
     </a>
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-Introduction">
    Pytorch Introduction
    <a class="anchor-link" href="#Pytorch-Introduction">
     ¶
    </a>
   </h2>
   <p>
    <a href="https://pytorch.org/">
     PyTorch
    </a>
    is an open source machine learning framework. 
You can find more information about PyTorch by following one of the
    <a href="https://pytorch.org/tutorials/">
     oficial tutorials
    </a>
    or by
    <a href="https://pytorch.org/docs/stable/">
     reading the documentation
    </a>
    .
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Import-Pythorch">
    Import Pythorch
    <a class="anchor-link" href="#Import-Pythorch">
     ¶
    </a>
   </h2>
   <p>
    <code>
     torch.cude.is_available()
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [141]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Import pytorch and check its version</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Is cuda available? </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>1.8.1
Is cuda available? False
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-Tensor">
    Pytorch Tensor
    <a class="anchor-link" href="#Pytorch-Tensor">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Initialization">
    Tensor Initialization
    <a class="anchor-link" href="#Tensor-Initialization">
     ¶
    </a>
   </h3>
   <p>
    <code>
     torch.tensor(),
    torch.from_numpy(),
    torch.zerors_like(),
    torch.ones_like(),
    torch.rand(),
    torch.ones(),
    torch.zeros(),
    torch.eye(),
    torch.full(),
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [142]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Initialization</span>

<span class="c1"># Directly from data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Direct Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_np</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># From a NumPy array</span>
<span class="n">np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">x_np</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Numpy Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_np</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># From another tensor:</span>
<span class="n">x_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Zeros Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_zeros</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">x_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Ones Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_ones</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">x_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">x_rand</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">rand_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">full_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">rand_tensor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Ones Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">ones_tensor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Zeros Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">zeros_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Full twos Tensor: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">full_tensor</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Direct Tensor: 
 tensor([[1, 2],
        [3, 4]]) 

Numpy Tensor: 
 tensor([[1, 2],
        [3, 4]]) 

Zeros Tensor: 
 tensor([[0, 0],
        [0, 0]]) 

Ones Tensor: 
 tensor([[1, 1],
        [1, 1]]) 

Random Tensor: 
 tensor([[0.3355, 0.0668],
        [0.2169, 0.7994]]) 

Random Tensor: 
 tensor([[0.0993, 0.1139, 0.0951],
        [0.6038, 0.0597, 0.6543]]) 

Ones Tensor: 
 tensor([[1., 1., 1.],
        [1., 1., 1.]]) 

Zeros Tensor: 
 tensor([[0., 0., 0.],
        [0., 0., 0.]])

Full twos Tensor: 
 tensor([[2, 2, 2],
        [2, 2, 2]])

</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Attributes">
    Tensor Attributes
    <a class="anchor-link" href="#Tensor-Attributes">
     ¶
    </a>
   </h3>
   <p>
    <code>
     tensor.dim(),
    tensor.shape,
    tensor.dtype,
    tensor.device,
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [143]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Atrributes</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Dimension of tensor: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Shape of tensor: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Datatype of tensor: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Device tensor is stored on: </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Dimension of tensor: 2

Shape of tensor: torch.Size([3, 4])

Datatype of tensor: torch.float32

Device tensor is stored on: cpu

</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Indexing">
    Tensor Indexing
    <a class="anchor-link" href="#Tensor-Indexing">
     ¶
    </a>
   </h3>
   <p>
    <code>
     tensor[start:stop:step]
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [144]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor slicing</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Get row 1, and all columns. </span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Single row:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Single column:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Get the first two rows and the last three columns</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">First two rows, last two columns:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Get every other row, and columns at index 1 and 2</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Every other row, middle columns:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])
shape:  torch.Size([3, 4])

Single row:
torch.Size([4]) tensor([5, 6, 7, 8])
shape:  torch.Size([4]) torch.Size([4])

Single column:
tensor([ 2,  6, 10])
shape:  torch.Size([3])

First two rows, last two columns:
tensor([[2, 3, 4],
        [6, 7, 8]])
shape:  torch.Size([2, 3])

Every other row, middle columns:
tensor([[ 2,  3],
        [10, 11]])
shape:  torch.Size([2, 2])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    More generally, given index arrays
    <code>
     idx0
    </code>
    and
    <code>
     idx1
    </code>
    with
    <code>
     N
    </code>
    elements each,
    <code>
     a[idx0, idx1]
    </code>
    is equivalent to:
   </p>
   <pre><code>torch.tensor([
  a[idx0[0], idx1[0]],
  a[idx0[1], idx1[1]],
  ...,
  a[idx0[N - 1], idx1[N - 1]]
])</code></pre>
   <p>
    (A similar pattern extends to tensors with more than two dimensions)
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [145]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Integer Index</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape: '</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># Index arrays can be int64 torch tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Reordered columns:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">])</span>


<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># Index arrays can be int64 torch tensors</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Index arrays can be int64 torch tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Reordered rows/columns:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])
shape:  torch.Size([3, 4])

Reordered columns:
tensor([[ 4,  3,  2,  1],
        [ 8,  7,  6,  5],
        [12, 11, 10,  9]])

Reordered rows/columns:
tensor([4, 7, 2])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [146]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Boolen indexing</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Mask tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># We can use the mask to construct a rank-1 tensor containing the elements of a</span>
<span class="c1"># that are selected by the mask</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Selecting elements with the mask:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>

<span class="c1"># We can also use boolean masks to modify tensors; for example this sets all</span>
<span class="c1"># elements &lt;= 3 to zero:</span>
<span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">After modifying with a mask:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[1, 2],
        [3, 4],
        [5, 6]])

Mask tensor:
tensor([[False, False],
        [False,  True],
        [ True,  True]])

Selecting elements with the mask:
tensor([4, 5, 6])

After modifying with a mask:
tensor([[0, 0],
        [0, 4],
        [5, 6]])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Operations">
    Tensor Operations
    <a class="anchor-link" href="#Tensor-Operations">
     ¶
    </a>
   </h3>
   <p>
    <code>
     tensor.cat(), torch.sum(), torch.mean(), torch.max(), torch.min(), torch.dot(),
    torch.mm(), torch.mv(), torch.addmm(), torch,addmv(),torch.bmm(), torch,baddmm(),
    torch.matmul(), torch.torch.broadcast_tensors()
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Tensor-Stacks">
    Tensor Stacks
    <a class="anchor-link" href="#Tensor-Stacks">
     ¶
    </a>
   </h4>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [147]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Operations</span>

<span class="c1"># Standard numpy-like indexing and slicing</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tensor</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">tensor</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">tensor</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># When use `torch.cat` and specify `dim=x`, then the dimension `x` will increase. </span>
<span class="n">t_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'horizontal cat:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">t_h</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="n">t_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'vetical cat:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">t_v</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># </span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 2., 1.],
        [1., 0., 1., 3.]])

horizontal cat:
 tensor([[1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 2., 1., 1., 0., 2., 1.],
        [1., 0., 1., 3., 1., 0., 1., 3.]])

vetical cat:
 tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 2., 1.],
        [1., 0., 1., 3.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 2., 1.],
        [1., 0., 1., 3.]])

</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Elementwise-Operations">
    Elementwise Operations
    <a class="anchor-link" href="#Elementwise-Operations">
     ¶
    </a>
   </h4>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [148]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Elementwise operations</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Elementwise sum; all give the same result</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Elementwise sum:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Elementwise difference</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Elementwise difference:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Elementwise product</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Elementwise product:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Elementwise division</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Elementwise division'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Elementwise power</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Elementwise power'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Elementwise sum:
tensor([[ 6.,  8., 10., 12.]])
tensor([[ 6.,  8., 10., 12.]])
tensor([[ 6.,  8., 10., 12.]])

Elementwise difference:
tensor([[-4., -4., -4., -4.]])
tensor([[-4., -4., -4., -4.]])
tensor([[-4., -4., -4., -4.]])

Elementwise product:
tensor([[ 5., 12., 21., 32.]])
tensor([[ 5., 12., 21., 32.]])
tensor([[ 5., 12., 21., 32.]])

Elementwise division
tensor([[0.2000, 0.3333, 0.4286, 0.5000]])
tensor([[0.2000, 0.3333, 0.4286, 0.5000]])
tensor([[0.2000, 0.3333, 0.4286, 0.5000]])

Elementwise power
tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])
tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])
tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Reduction-Operations">
    Reduction Operations
    <a class="anchor-link" href="#Reduction-Operations">
     ¶
    </a>
   </h4>
   <p>
    Reduction operations
    <em>
     reduce
    </em>
    the rank of tensors: the dimension over which you perform the reduction will be removed from the shape of the output. If you pass
    <code>
     keepdim=True
    </code>
    to a reduction operation, the specified dimension will not be removed; the output tensor will instead have a shape of 1 in that dimension.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [149]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Reduction</span>

<span class="c1"># When use reduction and specify `dim=x`, then the dimension `x` will be removed. </span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> 
                  <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Sum over entire tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># We can sum over each row:</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Sum of each row:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Sum over each column:</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Sum of each column:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[1., 2., 3.],
        [4., 5., 6.]])

Sum over entire tensor:
tensor(21.)

Sum of each row:
torch.Size([3])

Sum of each column:
tensor([ 6., 15.])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Matrix-Operations">
    Matrix Operations
    <a class="anchor-link" href="#Matrix-Operations">
     ¶
    </a>
   </h4>
   <ul>
    <li>
     <code>
      @
     </code>
     is used for multiplication, same as
     <code>
      torch.mm()
     </code>
     ,
     <code>
      torch.mv()
     </code>
     ,
     <code>
      torch.bmm()
     </code>
     ,
     <code>
      torch.bmv()
     </code>
    </li>
    <li>
     <code>
      torch.matmul()
     </code>
     <ul>
      <li>
       If both tensors are 1-dimensional, the dot product (scalar) is returned.
      </li>
      <li>
       If both arguments are 2-dimensional, the matrix-matrix product is returned.
      </li>
      <li>
       If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.
      </li>
      <li>
       If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.
      </li>
      <li>
       Support broadcasting
      </li>
     </ul>
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [150]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Matrix Operations</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># torch.dot</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> x0 shape: </span><span class="si">{</span><span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># torch.mm</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> x1 shape: </span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># torch.mv</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> x2 shape: </span><span class="si">{</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># torch.admm</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># m1 @ m2 + M</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> x3 shape: </span><span class="si">{</span><span class="n">x3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># torch.bmm</span>
<span class="n">bm1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">bm2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">x4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">bm1</span><span class="p">,</span> <span class="n">bm2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> x4 shape: </span><span class="si">{</span><span class="n">x4</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># torch.matmul()</span>
<span class="c1"># vector x vector</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> vector x vector </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># matrix x vector</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">' matrix x vector </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># batched matrix x broadcasted vector</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">' batched matrix x broadcasted vector </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># batched matrix x batched matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">' batched matrix x broadcasted vector </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># batched matrix x broadcasted matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">' batched matrix x broadcasted vector </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>
 x0 shape: torch.Size([])

 x1 shape: torch.Size([2, 3])

 x2 shape: torch.Size([2])

 x3 shape: torch.Size([2, 3])

 x4 shape: torch.Size([10, 3, 5])

 vector x vector torch.Size([])
 matrix x vector torch.Size([3])
 batched matrix x broadcasted vector torch.Size([10, 3])
 batched matrix x broadcasted vector torch.Size([10, 3, 5])
 batched matrix x broadcasted vector torch.Size([10, 3, 5])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Tensor-Broadcasting">
    Tensor Broadcasting
    <a class="anchor-link" href="#Tensor-Broadcasting">
     ¶
    </a>
   </h4>
   <ul>
    <li>
     Each tensor has at least one dimension.
    </li>
    <li>
     When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [151]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Broadcasting</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Here is x (before broadcasting):'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x.shape: '</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Here is v (before broadcasting):'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'v.shape: '</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">xx</span><span class="p">,</span> <span class="n">vv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_tensors</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Here is xx (after) broadcasting):'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'xx.shape: '</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Here is vv (after broadcasting):'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'vv.shape: '</span><span class="p">,</span> <span class="n">vv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Here is x (before broadcasting):
tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])
x.shape:  torch.Size([4, 3])

Here is v (before broadcasting):
tensor([1, 0, 1])
v.shape:  torch.Size([3])

Here is xx (after) broadcasting):
tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])
xx.shape:  torch.Size([4, 3])

Here is vv (after broadcasting):
tensor([[1, 0, 1],
        [1, 0, 1],
        [1, 0, 1],
        [1, 0, 1]])
vv.shape:  torch.Size([4, 3])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Data-Type">
    Tensor Data Type
    <a class="anchor-link" href="#Tensor-Data-Type">
     ¶
    </a>
   </h3>
   <p>
    <code>
     tensor.to(),
    tensor.new_zeros(),
    tensor.float(),
    tensor.double(),
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [152]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Data Type</span>

<span class="c1"># Let torch choose the datatype</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>   <span class="c1"># List of integers</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">])</span> <span class="c1"># List of floats</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># Mixed list</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'dtype when torch chooses for us:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'List of integers:'</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'List of floats:'</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Mixed list:'</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Force a particular datatype</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># 32-bit float</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>    <span class="c1"># 32-bit (signed) integer</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>    <span class="c1"># 64-bit (signed) integer</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">dtype when we force a datatype:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'32-bit float: '</span><span class="p">,</span> <span class="n">y0</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'32-bit integer: '</span><span class="p">,</span> <span class="n">y1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'64-bit integer: '</span><span class="p">,</span> <span class="n">y2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Other creation ops also take a dtype argument</span>
<span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Let torch choose for us</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span> <span class="c1"># 16-bit (signed) integer</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="c1"># 8-bit (unsigned) integer</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">torch.ones with different dtypes'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'default dtype:'</span><span class="p">,</span> <span class="n">z0</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'16-bit integer:'</span><span class="p">,</span> <span class="n">z1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'8-bit unsigned integer:'</span><span class="p">,</span> <span class="n">z2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># Cast to 32-bit float</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="c1"># Cast to 64-bit float</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Alternate way to cast to 32-bit float</span>
<span class="n">x4</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="c1"># Alternate way to cast to 64-bit float</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">x0:'</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x1:'</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x2:'</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x3:'</span><span class="p">,</span> <span class="n">x3</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x4:'</span><span class="p">,</span> <span class="n">x4</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c1"># Shape (3, 3), dtype torch.float64</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>               <span class="c1"># Shape (3, 3), dtype torch.float64</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>                 <span class="c1"># Shape (4, 5), dtype torch.float64</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>            <span class="c1"># Shape (6, 7), dtype torch.float64)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">x0 shape is </span><span class="si">%r</span><span class="s1">, dtype is </span><span class="si">%r</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x1 shape is </span><span class="si">%r</span><span class="s1">, dtype is </span><span class="si">%r</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x2 shape is </span><span class="si">%r</span><span class="s1">, dtype is </span><span class="si">%r</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x3 shape is </span><span class="si">%r</span><span class="s1">, dtype is </span><span class="si">%r</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">x3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x3</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>dtype when torch chooses for us:
List of integers: torch.int64
List of floats: torch.float32
Mixed list: torch.float32

dtype when we force a datatype:
32-bit float:  torch.float32
32-bit integer:  torch.int32
64-bit integer:  torch.int64

torch.ones with different dtypes
default dtype: torch.float32
16-bit integer: torch.int16
8-bit unsigned integer: torch.uint8

x0: torch.int64
x1: torch.float32
x2: torch.float64
x3: torch.float32
x4: torch.float64

x0 shape is torch.Size([3, 3]), dtype is torch.float64
x1 shape is torch.Size([3, 3]), dtype is torch.float64
x2 shape is torch.Size([4, 5]), dtype is torch.float64
x3 shape is torch.Size([6, 7]), dtype is torch.float64
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Reshape">
    Tensor Reshape
    <a class="anchor-link" href="#Tensor-Reshape">
     ¶
    </a>
   </h3>
   <p>
    <code>
     tensor.view(), tensor.reshape(), tensor.transpose(), tensor.permute(), tensor.contiguous()
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    The
    <code>
     view()
    </code>
    function takes elements in row-major order, so you cannot transpose matrices with
    <code>
     view()
    </code>
    .
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [153]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># tensor.view()</span>

<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Flatten x0 into a rank 1 vector of shape (8,)</span>
<span class="c1"># Takes elements in row-major order</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Flattened tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Rank 2 tensor</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Rank 2 tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># View x1 as shape (2, 2, 2)</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Rank 3 tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x3</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])
shape: torch.Size([2, 4])

Flattened tensor:
tensor([1, 2, 3, 4, 5, 6, 7, 8])
shape: torch.Size([8])

Rank 2 tensor:
shape: torch.Size([8, 1])

Rank 3 tensor:
shape: torch.Size([2, 2, 2])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [154]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor transpose and permute</span>

<span class="c1"># Create a tensor of shape (2, 3, 4)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
     <span class="p">[[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]],</span>
     <span class="p">[[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">]]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Original tensor:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Swap axes 1 and 2; shape is (2, 4, 3)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Swap axes 1 and 2:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Permute axes; the argument (1, 2, 0) means:</span>
<span class="c1"># - Make the old dimension 1 appear at dimension 0;</span>
<span class="c1"># - Make the old dimension 2 appear at dimension 1;</span>
<span class="c1"># - Make the old dimension 0 appear at dimension 2</span>
<span class="c1"># This results in a tensor of shape (3, 4, 2)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Permute axes'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'shape:'</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>Original tensor:
tensor([[[ 1,  2,  3,  4],
         [ 5,  6,  7,  8],
         [ 9, 10, 11, 12]],

        [[13, 14, 15, 16],
         [17, 18, 19, 20],
         [21, 22, 23, 24]]])
shape: torch.Size([2, 3, 4])

Swap axes 1 and 2:
tensor([[[ 1,  5,  9],
         [ 2,  6, 10],
         [ 3,  7, 11],
         [ 4,  8, 12]],

        [[13, 17, 21],
         [14, 18, 22],
         [15, 19, 23],
         [16, 20, 24]]])
torch.Size([2, 4, 3])

Permute axes
tensor([[[ 1, 13],
         [ 2, 14],
         [ 3, 15],
         [ 4, 16]],

        [[ 5, 17],
         [ 6, 18],
         [ 7, 19],
         [ 8, 20]],

        [[ 9, 21],
         [10, 22],
         [11, 23],
         [12, 24]]])
shape: torch.Size([3, 4, 2])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Test">
    Tensor Test
    <a class="anchor-link" href="#Tensor-Test">
     ¶
    </a>
   </h3>
   <p>
    <code>
     torch.all(), torch.is_close(), torch.all_close()
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-Range">
    Tensor Range
    <a class="anchor-link" href="#Tensor-Range">
     ¶
    </a>
   </h3>
   <p>
    <code>
     torch.arange(), torch.linspace()
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [ ]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor Range</span>

<span class="c1"># torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</span>
<span class="c1"># torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Tensor-GPU">
    Tensor GPU
    <a class="anchor-link" href="#Tensor-GPU">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [155]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Tensor on GPU</span>

<span class="c1"># Construct a tensor on the CPU</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'x0 device:'</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="c1"># Move it to the GPU using .to()</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'x1 device:'</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Move it to the GPU using .cuda()</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'x2 device:'</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Move it back to the CPU using .to()</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'x3 device:'</span><span class="p">,</span> <span class="n">x3</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Move it back to the CPU using .cpu()</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'x4 device:'</span><span class="p">,</span> <span class="n">x4</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># We can construct tensors directly on the GPU as well</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'y device / dtype:'</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Calling x.to(y) where y is a tensor will return a copy of x with the same</span>
    <span class="c1"># device and dtype as y</span>
    <span class="n">x5</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'x5 device / dtype:'</span><span class="p">,</span> <span class="n">x5</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">x5</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Cuda is not available.'</span> <span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>x0 device: cpu
Cuda is not available.
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-Autograd">
    Pytorch Autograd
    <a class="anchor-link" href="#Pytorch-Autograd">
     ¶
    </a>
   </h2>
   <p>
    <code>
     tensor.requires_grad_(), tensor.detach()
    </code>
   </p>
   <p>
    Every Tensor has a flag:
    <code>
     requires_grad
    </code>
    that allows for fine grained exclusion of subgraphs from gradient computation and can increase efficiency.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [156]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Pytorch autograd</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># requires_grad=False by default</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># requires_grad=False by default</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'a requires_grad: </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'b requires_grad: </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">requires_grad</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">b</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'z grad: </span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">z</span><span class="o">.</span><span class="n">grad</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>a requires_grad: False
b requires_grad: True
z grad: 
 tensor([[2., 2., 2., 2., 2.],
        [2., 2., 2., 2., 2.],
        [2., 2., 2., 2., 2.],
        [2., 2., 2., 2., 2.],
        [2., 2., 2., 2., 2.]])
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-DataLoader">
    Pytorch DataLoader
    <a class="anchor-link" href="#Pytorch-DataLoader">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-Transforms">
    Pytorch Transforms
    <a class="anchor-link" href="#Pytorch-Transforms">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Pytorch-Loss-Functions">
    Pytorch Loss Functions
    <a class="anchor-link" href="#Pytorch-Loss-Functions">
     ¶
    </a>
   </h2>
   <p>
    <code>
     torch.nn.MSELoss(), torch.nn.CrossEntropyLoss(),torch.nn.MultiLabelMarginLoss(),
    </code>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <a id="pytorch-section-mse-loss">
    </a>
   </p>
   <h3 id="MSELoss()">
    MSELoss()
    <a class="anchor-link" href="#MSELoss()">
     ¶
    </a>
   </h3>
   <ul>
    <li>
     Input: (N, )
    </li>
    <li>
     Target: (N, )
    </li>
    <li>
     Output: Scalar. If reduction is 'none', then (N,)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [157]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <a id="pytorch-section-cross-entropy-loss">
    </a>
   </p>
   <h3 id="CrossEntropyLoss()">
    CrossEntropyLoss()
    <a class="anchor-link" href="#CrossEntropyLoss()">
     ¶
    </a>
   </h3>
   <ul>
    <li>
     Input: (N, C), N is batch size, C is number of classes
    </li>
    <li>
     Target: (N,), $0 \leq target[i] \leq C-1 $
    </li>
    <li>
     Outtput: (N,)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [158]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Image pixel level classifiction for 5 classes</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <a id="pytorch-section-multi-label-margin-loss">
    </a>
   </p>
   <h3 id="MultiLabelMarginLoss()">
    MultiLabelMarginLoss()
    <a class="anchor-link" href="#MultiLabelMarginLoss()">
     ¶
    </a>
   </h3>
   <p>
    Creates a criterion that optimizes a multi-class multi-classification hinge loss. This means that for a sample x, it could have multiple correct labels.
   </p>
   <ul>
    <li>
     Input: (C,) or (N, C),  N is batch size, C is number of classes
    </li>
    <li>
     Target: (C) or (N, C), label targets after first -1 are ignored
    </li>
    <li>
     Output: Scalar. If reduction is 'none', then (N,)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [159]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MultiLabelMarginLoss</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="c1"># Single class hinge loss, so label == 3</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'single class loss: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.25</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.8</span><span class="o">-</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.8</span><span class="o">-</span><span class="mf">0.2</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.8</span><span class="o">-</span><span class="mf">0.4</span><span class="p">)))])</span>
<span class="k">assert</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expected</span><span class="p">))</span>

<span class="c1"># Multi-class hinge loss, so label == 3 and label == 1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'multi-class loss: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.25</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.1</span><span class="o">-</span><span class="mf">0.2</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.1</span><span class="o">-</span><span class="mf">0.4</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.8</span><span class="o">-</span><span class="mf">0.2</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="mf">0.8</span><span class="o">-</span><span class="mf">0.4</span><span class="p">)))])</span>
<span class="k">assert</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expected</span><span class="p">))</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
 <div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_subarea output_stream output_stdout output_text">
     <pre>single class loss: 0.3250
multi-class loss: 0.8500
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Torch-Activation-Functions">
    Torch Activation Functions
    <a class="anchor-link" href="#Torch-Activation-Functions">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <a id="pytorch-section-optimizer">
    </a>
   </p>
   <h2 id="Torch-Optimizer">
    Torch Optimizer
    <a class="anchor-link" href="#Torch-Optimizer">
     ¶
    </a>
   </h2>
   <p>
    <code>
     torch.optim.SGD(),torch.optim.RMSprop(), torch.optim.Adam()
    </code>
   </p>
   <p>
    <code>
     torch.optim
    </code>
    is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future. 
To use
    <code>
     torch.optim
    </code>
    you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.
   </p>
   <blockquote>
    <p>
     Note: If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. Parameters of a model after .cuda() will be different objects with those before the call.
    </p>
   </blockquote>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Construct-Optimizers">
    Construct Optimizers
    <a class="anchor-link" href="#Construct-Optimizers">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [ ]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Construct an optimizer</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Set-Parameter-Options">
    Set Parameter Options
    <a class="anchor-link" href="#Set-Parameter-Options">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    This means that
    <code>
     model.bas
    </code>
    e’s parameters will use the default learning rate of
    <code>
     1e-2
    </code>
    ,
    <code>
     model.classifier
    </code>
    ’s parameters will use a learning rate of
    <code>
     1e-3
    </code>
    , and a momentum of
    <code>
     0.9
    </code>
    will be used for all parameters.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [ ]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Set Parameter Options</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
                <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">()},</span>
                <span class="p">{</span><span class="s1">'params'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}</span>
                <span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Taking-an-Optimization-Step">
    Taking an Optimization Step
    <a class="anchor-link" href="#Taking-an-Optimization-Step">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing code_cell rendered">
 <div class="input">
  <div class="prompt input_prompt">
   In [ ]:
  </div>
  <div class="inner_cell">
   <div class="input_area collapsed">
    <div class="collapse_expand_button fa fa-1x fa-minus-square-o">
    </div>
    <div class="highlight hl-ipython3">
     <pre><span></span><span class="c1"># Taking an Optimization Step</span>
<span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="c1">#</span>
</pre>
    </div>
   </div>
  </div>
 </div>
</div>

<div> This blog is converted from <a href="https://github.com/xipengwang/xipengwang.github.io/tree/master/notebooks/machine-learning-pytorch.ipynb">machine-learning-pytorch.ipynb</a></div>